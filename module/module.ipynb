{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "vJ5lmAobxeKG"
      },
      "outputs": [],
      "source": [
        "character_columns=['name', 'department', 'departments', 'team', 'teams', 'product', 'products',\n",
        " 'region', 'regions', 'subject', 'subjects', 'class', 'school', 'schools',\n",
        " 'assignment', 'assignments', 'age group', 'age groups', 'disease', 'diseases',\n",
        " 'hospital', 'hospitals', 'city', 'cities', 'campaign', 'campaigns',\n",
        " 'platform', 'platforms', 'segment', 'segments', 'ad type', 'ad types',\n",
        " 'device', 'devices', 'app version', 'app versions', 'feature', 'features',\n",
        " 'day', 'days', 'error type', 'error types', 'country', 'countries', 'state', 'states',\n",
        " 'zone', 'zones', 'income bracket', 'income brackets', 'gender', 'genders',\n",
        " 'warehouse', 'warehouses', 'category', 'categories', 'supplier', 'suppliers',\n",
        " 'delivery route', 'delivery routes', 'shipment date', 'shipment dates',\n",
        " 'storage section', 'storage sections', 'developer', 'developers',\n",
        " 'module', 'modules', 'sprint', 'sprints', 'bug type', 'bug types',\n",
        " 'task', 'tasks', 'product type', 'product types', 'payment method',\n",
        " 'payment methods', 'customer', 'coupon', 'coupon codes', 'store branch',\n",
        " 'store branches', 'content type', 'content types', 'influencer',\n",
        " 'influencers', 'hashtag', 'hashtags', 'posting time', 'posting times',\n",
        " 'audience segment', 'audience segments', 'district', 'districts',\n",
        " 'scheme', 'schemes', 'utility', 'utility types', 'complaint type',\n",
        " 'complaint types', 'license category', 'license categories',\n",
        " 'player', 'players', 'match', 'matches', 'event', 'events',\n",
        " 'training', 'exercise', 'exercises', 'sleep day', 'meal', 'meals',\n",
        " 'expense category', 'expense categories', 'mood', 'book', 'books',\n",
        " 'course', 'courses', 'topic', 'topics', 'quiz', 'attempt', 'instructor',\n",
        " 'instructors', 'skill', 'skills', 'learning mode', 'learning modes',\n",
        " 'entry', 'entries', 'journal', 'peer', 'certificate', 'certificates']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "RiAGEGJnyTug"
      },
      "outputs": [],
      "source": [
        "time_columns=['date', 'dates', 'time', 'times', 'timestamp', 'timestamps', 'datetime', 'datetimes','month', 'months',\n",
        "              'week', 'weeks', 'day', 'days',\n",
        " 'quarter', 'quarters', 'year', 'years', 'time slot', 'time slots',\n",
        " 'date', 'dates', 'season', 'seasons', 'hour', 'hours',\n",
        " 'posting time', 'posting times', 'training day', 'sleep day',\n",
        " 'shipment date', 'shipment dates','qtr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "IybPX-9JU6Td"
      },
      "outputs": [],
      "source": [
        "location_terms = {\n",
        "    \"country\": [\n",
        "        \"country\", \"nation\", \"country_name\", \"nationality\", \"sovereign_state\",\n",
        "        \"land\", \"homeland\", \"country_code\", \"iso_country\", \"nation_name\",\n",
        "        \"odname\", \"dev\", \"world\", \"continent\", \"subcontinent\", \"subregion\",\n",
        "        \"member_state\", \"member_country\", \"state_party\"\n",
        "    ],\n",
        "    \"city\": [\n",
        "        \"city\", \"town\", \"municipality\", \"metro\", \"metropolis\", \"urban_area\",\n",
        "        \"city_name\", \"township\", \"borough\", \"capital\", \"village\", \"urban\",\n",
        "        \"metro_area\", \"conurbation\", \"settlement\", \"locality_name\"\n",
        "    ],\n",
        "    \"state\": [\n",
        "        \"state\", \"province\", \"region\", \"territory\", \"governorate\", \"prefecture\",\n",
        "        \"division\", \"county\", \"oblast\", \"subdivision\", \"federal_state\", \"administrative_area\",\n",
        "        \"state_name\", \"province_name\", \"region_name\", \"territory_name\", \"governorate_name\",\n",
        "        \"prefecture_name\", \"division_name\", \"county_name\", \"oblast_name\",\n",
        "        \"state_code\", \"province_code\", \"region_code\", \"territory_code\", \"governorate_code\",\n",
        "        \"prefecture_code\", \"division_code\", \"county_code\", \"oblast_code\",\n",
        "        \"state_id\", \"province_id\", \"region_id\", \"territory_id\", \"governorate_id\",\n",
        "        \"prefecture_id\", \"division_id\", \"county_id\", \"oblast_id\",\n",
        "        \"state_abbr\", \"province_abbr\", \"region_abbr\", \"territory_abbr\", \"governorate_abbr\",\n",
        "        \"prefecture_abbr\", \"division_abbr\", \"county_abbr\", \"oblast_abbr\",\n",
        "        \"state_iso\", \"province_iso\", \"region_iso\", \"territory_iso\", \"governorate_iso\",\n",
        "        \"prefecture_iso\", \"division_iso\", \"county_iso\", \"oblast_iso\",\n",
        "        \"reg\", \"reg_name\", \"reg_code\", \"reg_abbr\", \"reg_iso\", \"regname\",\n",
        "        \"statehood\", \"admin_region\", \"admin_division\", \"state_entity\"\n",
        "    ],\n",
        "    \"area\": [\n",
        "        \"area\", \"district\", \"locality\", \"zone\", \"subzone\", \"sector\",\n",
        "        \"ward\", \"neighborhood\", \"region_area\", \"block\", \"circle\", \"areaname\",\n",
        "        \"subdistrict\", \"tehsil\", \"taluka\", \"parish\", \"commune\", \"borough_area\"\n",
        "    ],\n",
        "    \"postal\": [\n",
        "        \"postal\",\"postalcode\", \"postal_code\", \"zipcode\", \"zip\", \"pin\", \"pincode\",\n",
        "        \"post_code\", \"mail_code\", \"zip_code\", \"postal_number\", \"postcode\",\n",
        "        \"delivery_code\", \"sorting_code\"\n",
        "    ],\n",
        "    \"address\": [\n",
        "        \"address\", \"street\", \"street_address\", \"road\", \"lane\", \"avenue\", \"drive\",\n",
        "        \"colony\", \"apartment\", \"flat\", \"building\", \"house_number\", \"location\",\n",
        "        \"residence\", \"unit\", \"plot\", \"lot\", \"address_line\"\n",
        "    ],\n",
        "    \"coordinates\": [\n",
        "        \"latitude\", \"lat\", \"longitude\", \"lon\", \"lng\", \"geo\",\n",
        "        \"geo_location\", \"coordinates\", \"x_coord\", \"y_coord\", \"geocode\",\n",
        "        \"latlon\", \"longlat\", \"gps\", \"spatial\", \"geom\"\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "U1Z3d9iQyoOy"
      },
      "outputs": [],
      "source": [
        "Numerical_columns=['id','sales', 'revenue', 'growth', 'expense', 'expenses', 'count', 'counts',\n",
        " 'score', 'scores', 'rating', 'ratings', 'completion', 'attendance',\n",
        " 'population', 'income', 'performance', 'progress', 'conversion',\n",
        " 'clicks', 'reach', 'usage', 'crashes', 'crash', 'frequency',\n",
        " 'GDP', 'engagement', 'vaccinations', 'mortality', 'patients',\n",
        " 'cases', 'admissions', 'footfall', 'impressions', 'views',\n",
        " 'capacity', 'volume', 'stats', 'mastery', 'attempts',\n",
        " 'coverage', 'distribution', 'amount', 'percent', 'percentage',\n",
        " 'rate', 'rates', 'spent', 'spend', 'return', 'budget', 'budgets',\n",
        " 'redemption', 'allocation', 'satisfaction', 'like', 'likes',\n",
        " 'share', 'shares', 'followers', 'follower', 'reach', 'ROI',\n",
        " 'usage', 'value', 'values', 'lead', 'leads', 'crashes',\n",
        " 'api calls', 'downloads', 'temperature', 'transactions',\n",
        " 'visits', 'visitors', 'literacy', 'energy', 'traffic',\n",
        " 'restock', 'delivery', 'orders', 'stock', 'quantity',\n",
        " 'damage', 'line', 'code', 'bugs', 'fixed', 'commits',\n",
        " 'test coverage', 'placed', 'purchases', 'calories',\n",
        " 'calorie', 'burned', 'speed', 'ranking', 'point', 'points',\n",
        " 'goals', 'score', 'completed', 'attempts', 'correct',\n",
        " 'answer', 'difficulty', 'duration', 'productivity',\n",
        " 'usage', 'conversion', 'engagement', 'impressions','avg','average']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "tLqga8W8cyQH"
      },
      "outputs": [],
      "source": [
        "Contact = [\"phone\",\"phone_number\",\"mobile\",\"mobile_number\",\"contact\",\"contact_number\",\n",
        "           \"telephone\",\"telephone_number\",\"cell\",\"cell_number\",\"phone_no\",\"mobile_no\",\n",
        "           \"contact_no\",\"tel_no\",\"primary_phone\",\"secondary_phone\",\"work_phone\",\"home_phone\",\n",
        "           \"office_phone\",\"personal_phone\",\"emergency_contact_number\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "SUM_COLUMNS = [\n",
        "    \"amount\", \"total_amount\", \"price\", \"unit_price\", \"cost\", \"total_cost\",\n",
        "    \"revenue\", \"sales\", \"net_sales\", \"gross_sales\", \"income\", \"profit\",\n",
        "    \"loss\", \"expense\", \"expenses\", \"billing_amount\", \"invoice_amount\",\n",
        "    \"payment\", \"paid_amount\", \"balance\", \"tax\", \"gst\", \"vat\", \"discount\",\n",
        "\n",
        "    \"order_value\", \"order_amount\", \"purchase_amount\", \"sale_amount\",\n",
        "    \"transaction_amount\", \"transaction_value\", \"cart_value\", \"subtotal\",\n",
        "    \"grand_total\",\n",
        "\n",
        "    \"weight\", \"total_weight\", \"volume\", \"total_volume\", \"area\",\n",
        "    \"distance\", \"total_distance\",\n",
        "\n",
        "    \"score\", \"total_score\", \"marks\", \"total_marks\", \"points\", \"total_points\",\n",
        "\n",
        "    \"time_spent\", \"duration\", \"total_time\", \"hours\", \"minutes\", \"seconds\",\n",
        "\n",
        "    \"units_consumed\", \"power_consumption\", \"fuel_consumption\",\n",
        "    \"electricity_units\", \"water_usage\", \"data_usage\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "puhZMBATReGd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "from os import replace\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv=[\"Breast_cancer_data.csv\",\"Canada.csv\",\"categories.csv\",\"Chocolate Sales.csv\",\"Diwali Sales Data.csv\",\"employees.csv\",\"full_order_details.csv\",\"Most Runs - 2022.csv\",\"order_details.csv\",\"Practicle 7 tableau_project_dataset (1).csv\",\"products.csv\",\"remain.csv\",\"sales_data_sample.csv\",\"Sales_Data_Big.csv\",\"Sample - Superstore.csv\",\"student_performance_dataset.csv\",\"superstore_sales.csv\",\"suppliers.csv\",\"test_sheet.csv\",\"try.csv\",\"x_y_axis_terms.csv\",\"Sales_without_NaNs.csv\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qRvNGasXuGy9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "suppliers.csv\n"
          ]
        }
      ],
      "source": [
        "i=17\n",
        "df=pd.read_csv(csv[i],encoding='unicode_escape')\n",
        "# df=pd.read_excel(\"Tableau Joins File.xlsx\")\n",
        "# df=pd.read_json(\"try.json\")\n",
        "print(csv[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "5s8Bl7NNKVvi"
      },
      "outputs": [],
      "source": [
        "total_column_count=0\n",
        "total_row_count=0\n",
        "column_name=[]\n",
        "null_columns=[]\n",
        "droped_column=[]\n",
        "numerical_columns=[]\n",
        "phone_number_column=[]\n",
        "alpha_columns=[]\n",
        "date_columns=[]\n",
        "location_columns=[]\n",
        "country=[]\n",
        "city=[]\n",
        "state=[]\n",
        "postal_code=[]\n",
        "area=[]\n",
        "address=[]\n",
        "coordinates=[]\n",
        "new_cols=[]\n",
        "shape=[]\n",
        "org_shape=df.shape\n",
        "summary=[\"org_shape\",\"shape\",\"total_column_count\",\"total_row_count\",\"column_name\",\n",
        "         \"null_columns\",\"droped_column\",\"numerical_columns\",\"alpha_columns\",\n",
        "         \"date_columns\",\"location_columns\",\"phone_number_column\",\"new_cols\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "shape=list(df.shape)\n",
        "df.columns = df.columns.str.strip().str.replace(r'\\s+', '_', regex=True).str.lower()\n",
        "df.drop_duplicates(inplace=True)\n",
        "column_name=df.columns\n",
        "null_columns=df.columns[df.isnull().any()].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvZxO7jKslbT",
        "outputId": "6402c5bb-92d2-4bd2-ebc6-015118a19099"
      },
      "outputs": [],
      "source": [
        "droped_column=[]\n",
        "for i in null_columns:\n",
        "  if (df[i].count()<= (len(df)//3)):\n",
        "    droped_column.append(i)\n",
        "    df.drop(columns=[i],inplace=True)\n",
        "total_column_count=len(df.columns)\n",
        "total_row_count=len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C1hKI5-cH2H",
        "outputId": "5da97f5a-2e68-490d-9c8d-fb9f2a355a31"
      },
      "outputs": [],
      "source": [
        "numerical_columns=df.select_dtypes(include=\"number\").columns.tolist()\n",
        "alpha_columns=df.select_dtypes(include=['object','string']).columns.tolist()\n",
        "date_columns=df.select_dtypes(include=['datetime']).columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "4XVB_KKZoTko"
      },
      "outputs": [],
      "source": [
        "#check date in numerical\n",
        "\n",
        "from os import replace\n",
        "for check_date in numerical_columns:\n",
        "  check=check_date.translate(str.maketrans(\"_-/\",\"   \")).split()\n",
        "  for i in check[:]:\n",
        "    for j in time_columns:\n",
        "      if i==j:\n",
        "        if check_date not in date_columns:\n",
        "          date_columns.append(check_date)\n",
        "        if check_date not in time_columns:\n",
        "          time_columns.append(check_date)\n",
        "          break\n",
        "        else:\n",
        "          break\n",
        "for r in date_columns:\n",
        "  if r in numerical_columns:\n",
        "    numerical_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "collapsed": true,
        "id": "7Ai9t1ejdg0X"
      },
      "outputs": [],
      "source": [
        "#check aplha column to dataset\n",
        "\n",
        "for j in alpha_columns:\n",
        "  for i in character_columns:\n",
        "    if j==i:\n",
        "      flag=0\n",
        "      break\n",
        "    flag=1\n",
        "  if flag==1:\n",
        "    character_columns.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "w-tw2uTUS0qu"
      },
      "outputs": [],
      "source": [
        "#check date column from dataset\n",
        "\n",
        "for i in alpha_columns:\n",
        "  for j in time_columns:\n",
        "    if i==j:\n",
        "      if i not in date_columns:\n",
        "        date_columns.append(i)\n",
        "      break\n",
        "for r in date_columns:\n",
        "  if r in alpha_columns:\n",
        "    alpha_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "OmLAvCfLT_Wk"
      },
      "outputs": [],
      "source": [
        "#check numerical column from dataset\n",
        "\n",
        "for i in alpha_columns:\n",
        "  for j in Numerical_columns:\n",
        "    if i==j:\n",
        "      if i not in numerical_columns:\n",
        "        try:\n",
        "          df[i]=df[i].astype(str).str.replace(r\"[,%$]\", \"\", regex=True).str.strip()\n",
        "          df[i]=pd.to_numeric(df[i],errors='ignore')\n",
        "        finally:\n",
        "          numerical_columns.append(i)\n",
        "      break\n",
        "for r in numerical_columns:\n",
        "  if r in alpha_columns:\n",
        "    alpha_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "-8VS5FJ-o2lp"
      },
      "outputs": [],
      "source": [
        "#numerical detector___________check later\n",
        "\n",
        "for i in alpha_columns:\n",
        "    for j in Numerical_columns:\n",
        "        pattern = (\n",
        "            r'(^' + re.escape(j) + r'$|' +\n",
        "            r'^' + re.escape(j) + r'([_\\-\\s]|$)|' +\n",
        "            r'([_\\-\\s]|^)' + re.escape(j) + r'$|' +\n",
        "            r'.*'+re.escape(j)+r'.*'\n",
        "            r')'\n",
        "        )\n",
        "        if re.search(pattern, i, re.IGNORECASE):\n",
        "            if i not in numerical_columns:\n",
        "              v=df.loc[0,i]\n",
        "              val=\"1234567890%.$-*+\"\n",
        "              nflag=0\n",
        "              for fst in v:\n",
        "                if fst in val:\n",
        "                  nflag=nflag+1\n",
        "              if nflag==(len(v)):\n",
        "                df[i]=(df[i]\n",
        "                  .astype(str)\n",
        "                  .str.replace(r\"[,_\\-%\\$\\*]\", \"\", regex=True)\n",
        "                  .str.strip()\n",
        "                  )\n",
        "                df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "                numerical_columns.append(i)\n",
        "              break\n",
        "\n",
        "for r in numerical_columns:\n",
        "    if r in alpha_columns:\n",
        "        alpha_columns.remove(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "nYFAz6SrskGV"
      },
      "outputs": [],
      "source": [
        "#date time detector\n",
        "\n",
        "for i in alpha_columns:\n",
        "    for j in time_columns:\n",
        "        pattern = (\n",
        "            r'(^' + re.escape(j) + r'$|' +\n",
        "            r'^' + re.escape(j) + r'([_\\-\\s]|$)|' +\n",
        "            r'([_\\-\\s]|^)' + re.escape(j) + r'$|' +\n",
        "            r'.*' + re.escape(j) + r'.*'\n",
        "            r')'\n",
        "        )\n",
        "        if re.search(pattern, i, re.IGNORECASE):\n",
        "            if i not in date_columns:\n",
        "                date_columns.append(i)\n",
        "            break\n",
        "\n",
        "def detect_and_convert_date(col,fmt,check):\n",
        "    col = col.astype(str).str.strip()\n",
        "    if col.str.fullmatch(r\"\\d{1,2}\").all():\n",
        "        return col.astype(int), None, None\n",
        "    if col.str.fullmatch(r\"\\d{2,4}\").all():\n",
        "        return col.astype(int), None, None\n",
        "    if check[0:4].isdigit():\n",
        "        fmt=\"%Y-%m-%d\"\n",
        "    if len(check)>10:\n",
        "        fmt=\"%m-%d-%Y %H:%M:%S.%f\"\n",
        "    parsed = pd.to_datetime(col, errors=\"coerce\", format=fmt)\n",
        "    if parsed.isnull().all():\n",
        "        fmt=\"%m-%d-%Y\"\n",
        "        parsed = pd.to_datetime(col, errors=\"coerce\")\n",
        "    month_col = parsed.dt.month\n",
        "    year_col = parsed.dt.year\n",
        "    return parsed.dt.strftime(fmt), month_col,year_col\n",
        "for r in date_columns:\n",
        "    df[r]=df[r].replace(\"/\",\"-\")\n",
        "    fmt=\"%d-%m-%Y\"\n",
        "    check = df.loc[0,r]\n",
        "    check = str(check).strip()\n",
        "    try:\n",
        "        if (check[3] in ['-','/'] and check[4].isalpha()) or (check[3].lower().isalpha()):\n",
        "            flag=2\n",
        "            df[r]=df[r].astype(str).str.lower().str.strip()\n",
        "            df[r]=df[r].replace({\"jan\":\"01\",\"feb\":\"02\",\"mar\":\"03\",\"apr\":\"04\",\"may\":\"05\",\"jun\":\"06\",\n",
        "                             \"jul\":\"07\",\"aug\":\"08\",\"sep\":\"09\",\"oct\":\"10\",\"nov\":\"11\",\"dec\":\"12\",\"january\":\"01\",\n",
        "                             \"february\":\"02\",\"march\":\"03\",\"april\":\"04\",\"june\":\"06\",\n",
        "                             \"july\":\"07\",\"august\":\"08\",\"september\":\"09\",\"october\":\"10\",\n",
        "                             \"november\":\"11\",\"december\":\"12\"},\n",
        "                            regex=True)\n",
        "            df[r] = pd.to_datetime(df[r],errors=\"coerce\",format=\"%d-%m-%y\").dt.strftime(\"%d-%m-%y\")\n",
        "            if len(df.loc[0,r])==8:\n",
        "                fmt=\"%d-%m-%y\"\n",
        "    except IndexError:\n",
        "        fmt=\"%d-%m-%Y\"\n",
        "    finally:\n",
        "        df[r], month,year = detect_and_convert_date(df[r],fmt,check)\n",
        "        if month is not None:\n",
        "            df[r + \"_month\"] = month\n",
        "            new_cols.append(r + \"_month\")\n",
        "        \n",
        "        if year is not None:\n",
        "            df[r + \"_year\"] = year\n",
        "            new_cols.append(r + \"_year\")\n",
        "    \n",
        "        if r in alpha_columns:\n",
        "            alpha_columns.remove(r)\n",
        "for new in new_cols:\n",
        "    date_columns.append(new)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter duplicate date columns\n",
        "\n",
        "r=[]\n",
        "for i in new_cols:\n",
        "    for j in date_columns:\n",
        "        count=len(df)-1\n",
        "        check=0\n",
        "        for k in range(0,len(df)-1):\n",
        "            if df.loc[k,i]==df.loc[k,j] and i!=j:\n",
        "                check=check+1\n",
        "            else:\n",
        "                break\n",
        "        if count==check:\n",
        "            r.append(i)\n",
        "            \n",
        "for i in r:\n",
        "    date_columns.remove(i)\n",
        "    df.drop(columns=[i],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "column_name=df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ChCVWe_pZTVc"
      },
      "outputs": [],
      "source": [
        "#Location detector\n",
        "\n",
        "for i in location_terms:\n",
        "  for j in range(len(location_terms[i])):\n",
        "    for k in alpha_columns:\n",
        "      if k==location_terms[i][j]:\n",
        "        if k not in location_columns:\n",
        "          location_columns.append(k)\n",
        "          if i==\"country\":\n",
        "            country.append(k)\n",
        "          elif i==\"city\":\n",
        "            city.append(k)\n",
        "          elif i==\"state\":\n",
        "            state.append(k)\n",
        "          elif i==\"area\":\n",
        "            area.append(k)\n",
        "          elif i==\"postal\":\n",
        "            postal_code.append(k)\n",
        "          elif i==\"address\":\n",
        "            address.append(k)\n",
        "          elif i==\"coordinates\":\n",
        "            coordinates.append(k)\n",
        "    for n in numerical_columns:\n",
        "      if n==location_terms[i][j]:\n",
        "        if n not in location_columns:\n",
        "          location_columns.append(n)\n",
        "          if i==\"postal\":\n",
        "            postal_code.append(n)\n",
        "for r in location_columns:\n",
        "  if r in alpha_columns:\n",
        "    alpha_columns.remove(r)\n",
        "for rn in location_columns:\n",
        "  if rn in numerical_columns:\n",
        "    numerical_columns.remove(rn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jpxLyQ3cKfW",
        "outputId": "076ccdc1-f8ab-46b8-cb32-ebc94d6fffbb"
      },
      "outputs": [],
      "source": [
        "#non alphabetical pushed to numerical\n",
        "\n",
        "for i in alpha_columns:\n",
        "  flag=0\n",
        "  add=0\n",
        "  sub=0\n",
        "  nct=0\n",
        "  fstvl=0\n",
        "  lstvl=0\n",
        "  special=0\n",
        "  value=df.loc[0,i]\n",
        "  val=\"1234567890\"\n",
        "  alpha = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "  Alpha = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "  if (len(value)==1) and ((value in alpha) or (value in Alpha)):\n",
        "    continue\n",
        "    if isinstance(value, str):\n",
        "      val=\"1234567890\"\n",
        "      vald=\"1234567890.\"\n",
        "      value=value.replace(\",\",\"\").strip()\n",
        "      for tr in range(len(value)):\n",
        "        if (value[tr] not in val) and (value[tr]==value[0]):\n",
        "          fstvl=1\n",
        "        elif (value[tr] not in val) and (value[tr]==value[-1]):\n",
        "          lstvl=1\n",
        "        elif (value[tr] in val):\n",
        "          flag=flag+1\n",
        "        elif (value[tr]==\".\"):\n",
        "          flag=flag+1\n",
        "          special=special+1\n",
        "    if (fstvl==1) and ((len(value)-1)==flag):\n",
        "      for cv in range(len(df[i])):\n",
        "        val_str = str(df.loc[cv, i])\n",
        "        for see in val_str:\n",
        "          if (sub==0) and (see==\"-\"):\n",
        "            sub=1\n",
        "          elif see not in vald:\n",
        "            val_str = val_str.replace(see, \"\")\n",
        "        df.loc[cv, i] = val_str\n",
        "      df[i]=(df[i]\n",
        "            .astype(str)\n",
        "            .str.replace(\",\",\"\",regex=False)\n",
        "            .str.strip()\n",
        "            )\n",
        "      df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "      numerical_columns.append(i)\n",
        "    elif (lstvl==1) and ((len(value)-1)==flag):\n",
        "      for cv in range(len(df[i])):\n",
        "        val_str = str(df.loc[cv, i])\n",
        "        for see in val_str:\n",
        "          if (sub==0) and (see==\"-\"):\n",
        "            sub=1\n",
        "          elif see not in vald:\n",
        "            val_str = val_str.replace(see, \"\")\n",
        "        df.loc[cv, i] = val_str\n",
        "      df[i]=(df[i]\n",
        "            .astype(str)\n",
        "            .str.replace(\",\",\"\",regex=False)\n",
        "            .str.strip()\n",
        "            )\n",
        "      df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "      numerical_columns.append(i)\n",
        "    elif (special==1) and ((len(value))==flag):\n",
        "      for cv in range(len(df[i])):\n",
        "        val_str = str(df.loc[cv, i])\n",
        "        for see in val_str:\n",
        "          if (sub==0) and (see==\"-\"):\n",
        "            sub=1\n",
        "          elif see not in vald:\n",
        "            val_str = val_str.replace(see, \"\")\n",
        "        df.loc[cv, i] = val_str\n",
        "      df[i]=(df[i]\n",
        "            .astype(str)\n",
        "            .str.replace(\",\",\"\",regex=False)\n",
        "            .str.strip()\n",
        "            )\n",
        "      df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "      numerical_columns.append(i)\n",
        "    elif (special==0) and ((len(value))==flag) and (lstvl==0) and (fstvl==0):\n",
        "      for cv in range(len(df[i])):\n",
        "        val_str = str(df.loc[cv, i])\n",
        "        for see in val_str:\n",
        "          if (sub==0) and (see==\"-\"):\n",
        "            sub=1\n",
        "          elif see not in vald:\n",
        "            val_str = val_str.replace(see, \"\")\n",
        "        df.loc[cv, i] = val_str\n",
        "      df[i]=(df[i]\n",
        "            .astype(str)\n",
        "            .str.replace(\",\",\"\",regex=False)\n",
        "            .str.strip()\n",
        "            )\n",
        "      df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "      numerical_columns.append(i)\n",
        "  else:\n",
        "    value=str(value).strip()\n",
        "    if value.isdigit():\n",
        "      df[i]=df[i].astype(str).str.strip()\n",
        "      df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "      numerical_columns.append(i)\n",
        "    elif (isinstance(value,str)):\n",
        "      for cv in value:\n",
        "        if cv in val:\n",
        "          nct=nct+1\n",
        "      if len(value)==nct:\n",
        "        df[i]=(df[i]\n",
        "            .astype(str)\n",
        "            .str.replace(r\"[,_\\-%\\$\\*]\", \"\", regex=True)\n",
        "            .str.strip()\n",
        "            )\n",
        "        df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "        numerical_columns.append(i)\n",
        "\n",
        "for r in numerical_columns:\n",
        "  if r in alpha_columns:\n",
        "    alpha_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "L635K18PYyYR"
      },
      "outputs": [],
      "source": [
        "#non numerical pushed to alphabetical\n",
        "\n",
        "for i in numerical_columns:\n",
        "  flag=0\n",
        "  add=0\n",
        "  sub=0\n",
        "  value = df.loc[0, i]\n",
        "  if isinstance(value, str):\n",
        "    val=\"1234567890\"\n",
        "    vald=\"1234567890.\"\n",
        "    alpha=\"abcdefghijklmnopqrstuvwxyz\"\n",
        "    Alpha=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "    value=value.replace(\",\",\"\").strip()\n",
        "    for tr in range(1,len(value)):\n",
        "      if (isinstance(value[0],str) and (value[tr] in val) ) or ((value[0] in val) and (value[tr] in val)) or ((value[tr-1] in val) and (isinstance(value[-1],str))):\n",
        "        flag=1\n",
        "      elif (value[tr] == \".\"):\n",
        "        flag=1\n",
        "      else:\n",
        "        add=add+1\n",
        "  flag=flag+add\n",
        "  if (flag==1) and (((value[0] not in alpha) and (value[0] not in Alpha)) and ((value[-1] not in alpha) and (value[-1] not in Alpha))):\n",
        "    if len(df[i])<=100:\n",
        "        check_len=len(df[i])\n",
        "    else:\n",
        "        check_len=60\n",
        "    n=np.random.randint(1, len(df[i])//3)\n",
        "    for cv in range(n,check_len):\n",
        "      val_str = str(df.loc[cv, i])\n",
        "      for see in val_str:\n",
        "        if (sub==0) and (see==\"-\"):\n",
        "          sub=1\n",
        "        elif (see not in vald):\n",
        "          val_str = val_str.replace(see, \"\")\n",
        "      df.loc[cv, i] = val_str\n",
        "    df[i] = (\n",
        "    df[i]\n",
        "    .astype(str)\n",
        "    .str.replace(\",\", \"\", regex=False)\n",
        "    .str.strip())\n",
        "    df[i] = pd.to_numeric(df[i], errors=\"coerce\")\n",
        "  elif (flag>1) or ((flag==1) and (((value[0] in alpha) or (value[0] in Alpha)) or ((value[-1] in alpha) or (value[-1] in Alpha)))):\n",
        "    alpha_columns.append(i)\n",
        "for r in alpha_columns:\n",
        "  if r in numerical_columns:\n",
        "    numerical_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "nOvJ_WP8cDZc"
      },
      "outputs": [],
      "source": [
        "#phone number detector from numerical column\n",
        "for i in numerical_columns:\n",
        "  if i in Contact:\n",
        "    phone_number_column.append(i)\n",
        "    numerical_columns.remove(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Qt_PhwwyGTxT"
      },
      "outputs": [],
      "source": [
        "#filter alpha columns\n",
        "for r in alpha_columns:\n",
        "  if r in numerical_columns:\n",
        "    alpha_columns.remove(r)\n",
        "  elif r in date_columns:\n",
        "    alpha_columns.remove(r)\n",
        "  elif r in location_columns:\n",
        "    alpha_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "LdqX0DBSSet6"
      },
      "outputs": [],
      "source": [
        "#formatting alpha columns\n",
        "for i in alpha_columns:\n",
        "  df[i]=df[i].str.strip()\n",
        "  df[i]=df[i].str.title()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "shape=list(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in numerical_columns:\n",
        "    unique_vals=set(df[i].dropna().unique())\n",
        "    if unique_vals.issubset({1,0}):\n",
        "        SUM_COLUMNS.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in alpha_columns:\n",
        "    df[col] = df[col].astype(str).str.lower().str.strip()\n",
        "    unique_vals = set(df[col].dropna().unique())\n",
        "    if unique_vals.issubset({\"yes\", \"no\", \"y\", \"n\"}):\n",
        "        df[col] = df[col].replace(\n",
        "            {\"yes\": 1, \"no\": 0, \"y\": 1, \"n\": 0}\n",
        "        )\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "        numerical_columns.append(col)\n",
        "        SUM_COLUMNS.append(col)\n",
        "    elif unique_vals.issubset({\"true\", \"false\"}):\n",
        "        df[col] = df[col].replace(\n",
        "            {\"true\": 1, \"false\": 0}\n",
        "        )\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "        numerical_columns.append(col)\n",
        "        SUM_COLUMNS.append(col)\n",
        "    elif unique_vals.issubset({\"m\", \"f\"}):\n",
        "        df[col] = df[col].replace(\n",
        "            {\"m\": \"Male\", \"f\": \"Female\"}\n",
        "        )\n",
        "    if col not in numerical_columns:\n",
        "        df[col] = df[col].str.title()\n",
        "alpha_columns = [c for c in alpha_columns if c not in numerical_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "COUNT_COLUMNS= [\n",
        "    \"quantity\", \"qty\", \"count\", \"number\", \"no\", \"items\", \"units\",\n",
        "    \"records\", \"entries\", \"cases\", \"instances\", \"samples\",\n",
        "    \"observations\",\n",
        "\n",
        "    \"form\", \"submission\", \"response\", \"application\", \"request\",\n",
        "    \"complaint\", \"feedback\",\n",
        "\n",
        "    \"signup\", \"registration\", \"login\", \"logout\", \"activity\",\n",
        "    \"action\", \"interaction\", \"event\",\n",
        "\n",
        "    \"page_view\", \"impression\", \"hit\", \"visit\", \"session\",\n",
        "    \"bounce\", \"conversion\", \"lead\",\n",
        "\n",
        "    \"error\", \"warning\", \"failure\", \"crash\", \"alert\", \"incident\",\n",
        "    \"issue\", \"ticket\",\n",
        "\n",
        "    \"attendance\", \"enrollment\", \"exam\", \"test\", \"attempt\",\n",
        "\n",
        "    \"appointment\", \"diagnosis\", \"procedure\", \"followup\",\n",
        "\n",
        "    \"cart\", \"order_count\", \"product_view\", \"wishlist\",\n",
        "    \"return\", \"shipment\", \"delivery\",\n",
        "\n",
        "    \"status\", \"flag\", \"label\", \"tag\", \"type\", \"category\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "dct=0\n",
        "lct=0\n",
        "for i in alpha_columns:\n",
        "    check=df.loc[0,i]\n",
        "    for j in check:\n",
        "        if j.isdigit():\n",
        "           dct+=1\n",
        "        elif j==\"-\":\n",
        "            lct+=1\n",
        "    if dct+lct==len(check):\n",
        "        COUNT_COLUMNS.append(i)\n",
        "    dct=0\n",
        "    lct=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in alpha_columns:\n",
        "    df[i]=df[i].fillna(\"Unknown\")\n",
        "for i in numerical_columns:\n",
        "    df[i]=df[i].fillna(df[i].median())\n",
        "for i in location_columns:\n",
        "    df[i]=df[i].fillna(\"Unknown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i in summary:\n",
        "#     print(f\"{i}:-\\n{eval(i)}\\n\")\n",
        "# for i in df.columns:\n",
        "#     print(f\"{i}\\n{df[i].describe()}\\n\")\n",
        "# print(df.head())\n",
        "# print(df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "#graph col:-\n",
        "X_Qualitative=[]\n",
        "X_Quantitative=[]\n",
        "X_Location=[]\n",
        "X_Time=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in column_name:\n",
        "    a=len(df[i].unique())\n",
        "    if a<=15 :\n",
        "        if i in alpha_columns:\n",
        "            X_Qualitative.append(i)\n",
        "        elif i in numerical_columns:\n",
        "            X_Quantitative.append(i)\n",
        "        elif i in date_columns:\n",
        "            X_Time.append(i)\n",
        "# print(X_Qualitative)\n",
        "# print(X_Quantitative)\n",
        "# print(X_Time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "single=[]\n",
        "N_single=[]\n",
        "P_single=[]\n",
        "mix=[]\n",
        "N_mix=[]\n",
        "L_mix=[]\n",
        "P_mix=[]\n",
        "line_charts=[]\n",
        "heat_maps=[]\n",
        "histogram_charts=[]\n",
        "scatter_plots=[]\n",
        "box_plots=[]\n",
        "area_charts=[]\n",
        "bubble_charts = []\n",
        "dia=[single,N_single,P_single,mix,N_mix,L_mix,P_mix,line_charts,heat_maps,histogram_charts,scatter_plots,box_plots,area_charts,bubble_charts]\n",
        "Dia_ID=[]\n",
        "Access=[]\n",
        "bar_check=[]\n",
        "def check(i,a,bar_check,p):\n",
        "    if Access[i][a] and (i!=6 and i!=2) and (p==0):\n",
        "        p=dia[int(Access[i][a][0])][int(Access[i][a][1])][int(Access[i][a][2])][int(Access[i][a][3])]\n",
        "        bar_check.append(Access[i][a])\n",
        "        a+=1\n",
        "    return a,bar_check,p\n",
        "def B_check(i,bar_check,p):\n",
        "    if Access[i][0] and (i!=6 and i!=2) and (p==0) and Access[i][0] not in bar_check:\n",
        "        p=dia[int(Access[i][0][0])][int(Access[i][0][1])][int(Access[i][0][2])][int(Access[i][0][3])]\n",
        "        bar_check.append(Access[i][0])\n",
        "    return bar_check,p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "def four(column,u4,a,b,c,d,A,B,C,D):\n",
        "    for i in column:\n",
        "        check=len(df[i].unique())\n",
        "        if check>1 and check<5:\n",
        "            new=df[i].value_counts()\n",
        "            for i in len(new):\n",
        "                if new.index[i] not in u4:\n",
        "                    if a==0:\n",
        "                        a=new.values[i]\n",
        "                        u4.append(a)\n",
        "                        A=new.index[i]\n",
        "                    elif b==0:\n",
        "                        b=new.values[i]\n",
        "                        u4.append(b)\n",
        "                        B=new.index[i]\n",
        "                    elif c==0:\n",
        "                        c=new.values[i]\n",
        "                        u4.append(c)\n",
        "                        C=new.index[i]\n",
        "                    elif d==0:\n",
        "                        d=new.values[i]\n",
        "                        u4.append[d]\n",
        "                        D=new.index[i]\n",
        "    return u4,a,b,c,d,A,B,C,D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "u4=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "a=0\n",
        "b=0\n",
        "c=0\n",
        "d=0\n",
        "A=0\n",
        "B=0\n",
        "C=0\n",
        "D=0\n",
        "\n",
        "try:\n",
        "    for i in numerical_columns:\n",
        "        if df[i].sum() not in u4 and a==0:\n",
        "            a=df[i].sum()\n",
        "            u4.append(a)\n",
        "            A=\"Total \"+i\n",
        "        elif df[i].sum() not in u4 and b==0:\n",
        "            b=df[i].sum()\n",
        "            u4.append(b)\n",
        "            B=\"Total \"+i\n",
        "        elif df[i].sum() not in u4 and c==0:\n",
        "            c=df[i].sum()\n",
        "            u4.append(c)\n",
        "            C=\"Total \"+i\n",
        "        elif df[i].sum() not in u4:\n",
        "            d=df[i].sum()\n",
        "            u4.append(d)\n",
        "            D=\"Total \"+i\n",
        "except:\n",
        "    try:\n",
        "        u4,a,b,c,d,A,B,C,D=four(alpha_columns,u4,a,b,c,d,A,B,C,D)\n",
        "    except:\n",
        "        u4,a,b,c,d,A,B,C,D=four(location_columns,u4,a,b,c,d,A,B,C,D)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "column_name = df.columns\n",
        "result = {col: [] for col in column_name}\n",
        "pie_result = {col: [] for col in column_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "spec_col=[[],[],[],[],[],[],[]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar charts>>>\n",
        "j=0\n",
        "k=0\n",
        "\n",
        "for col_index, col_name in enumerate(X_Qualitative):\n",
        "    unique_vals = df[col_name].unique()\n",
        "    if len(unique_vals) < 3 or len(unique_vals)>15:\n",
        "        single.append([])\n",
        "        if numerical_columns in SUM_COLUMNS:\n",
        "            grouped = df.groupby(col_name)[numerical_columns].sum()\n",
        "        else:\n",
        "            grouped = df.groupby(col_name)[numerical_columns].count()\n",
        "        spec_col[0].append([col_name,numerical_columns])\n",
        "        i=0\n",
        "        for category in unique_vals:\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=numerical_columns,\n",
        "                y=grouped.loc[category],\n",
        "                text=grouped.loc[category],\n",
        "                hovertemplate=\n",
        "                \"<b>Column:</b> %{x}<br>\" +\n",
        "                \"<b>Value:</b> %{y}<br>\" +\n",
        "                \"<extra></extra>\"\n",
        "            ))\n",
        "            fig.update_layout(\n",
        "                title=f\"{category} summary for column {col_name}\",\n",
        "                xaxis_title=\"Numerical Columns\",\n",
        "                yaxis_title=\"Sum\",\n",
        "                hoverlabel=dict(bgcolor=\"white\")\n",
        "            )\n",
        "            single[j].append([])\n",
        "            single[j][i].append(fig)\n",
        "            result[col_name].append(fig)\n",
        "\n",
        "            i=i+1\n",
        "        j=j+1\n",
        "    else:\n",
        "        mix.append([])\n",
        "        si=0\n",
        "        for num_col in numerical_columns:\n",
        "            if num_col in SUM_COLUMNS:\n",
        "                grouped = df.groupby(col_name)[num_col].sum()\n",
        "            else:\n",
        "                grouped = df.groupby(col_name)[num_col].count()\n",
        "            spec_col[3].append([col_name,num_col])\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=grouped.index,\n",
        "                y=grouped.values,\n",
        "                text=grouped.values,\n",
        "                hovertemplate=\n",
        "                \"<b>Category:</b> %{x}<br>\" +\n",
        "                \"<b>Value:</b> %{y}<br>\" +\n",
        "                \"<extra></extra>\"\n",
        "            ))\n",
        "            fig.update_layout(\n",
        "                title=f\"{num_col} by {col_name}\",\n",
        "                xaxis_title=col_name,\n",
        "                yaxis_title=num_col\n",
        "            )\n",
        "            mix[k].append([])\n",
        "            mix[k][si].append(fig)\n",
        "            result[col_name].append(fig)\n",
        "            result[num_col].append(fig)\n",
        "            si=si+1\n",
        "        k=k+1\n",
        "\n",
        "j=0\n",
        "k=0\n",
        "\n",
        "\n",
        "for col_index, col_name in enumerate(X_Quantitative):\n",
        "    unique_vals = df[col_name].unique()\n",
        "    if len(unique_vals) < 3:\n",
        "        N_single.append([])\n",
        "        if numerical_columns in SUM_COLUMNS:\n",
        "            grouped = df.groupby(col_name)[numerical_columns].sum()\n",
        "        else:\n",
        "            grouped = df.groupby(col_name)[numerical_columns].count()\n",
        "        spec_col[1].append([col_name,numerical_columns])\n",
        "        i=0\n",
        "        for category in unique_vals:\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=numerical_columns,\n",
        "                y=grouped.loc[category],\n",
        "                text=grouped.loc[category],\n",
        "                hovertemplate=\n",
        "                \"<b>Column:</b> %{x}<br>\" +\n",
        "                \"<b>Value:</b> %{y}<br>\" +\n",
        "                \"<extra></extra>\"\n",
        "            ))\n",
        "            fig.update_layout(\n",
        "                title=f\"{category} summary for column {col_name}\",\n",
        "                xaxis_title=\"Numerical Columns\",\n",
        "                yaxis_title=\"Sum\",\n",
        "                hoverlabel=dict(bgcolor=\"white\")\n",
        "            )\n",
        "            N_single[j].append([])\n",
        "            N_single[j][i].append(fig)\n",
        "            result[col_name].append(fig)\n",
        "            i=i+1\n",
        "        j=j+1\n",
        "            \n",
        "\n",
        "    else:\n",
        "        N_mix.append([])\n",
        "        si=0\n",
        "        for num_col in numerical_columns:\n",
        "            if num_col in SUM_COLUMNS:\n",
        "                grouped = df.groupby(col_name)[num_col].sum()\n",
        "            else:\n",
        "                grouped = df.groupby(col_name)[num_col].count()\n",
        "            spec_col[4].append([col_name,num_col])\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=grouped.index,\n",
        "                y=grouped.values,\n",
        "                text=grouped.values,\n",
        "                hovertemplate=\n",
        "                \"<b>Category:</b> %{x}<br>\" +\n",
        "                \"<b>Value:</b> %{y}<br>\" +\n",
        "                \"<extra></extra>\"\n",
        "            ))\n",
        "            fig.update_layout(\n",
        "                title=f\"{num_col} by {col_name}\",\n",
        "                xaxis_title=col_name,\n",
        "                yaxis_title=num_col\n",
        "            )\n",
        "            N_mix[k].append([])\n",
        "            N_mix[k][si].append(fig)\n",
        "            result[col_name].append(fig)\n",
        "            result[num_col].append(fig)\n",
        "            si=si+1\n",
        "        k=k+1\n",
        "\n",
        "j=0\n",
        "\n",
        "for col_index, col_name in enumerate(location_columns):\n",
        "    L_mix.append([])\n",
        "    si=0\n",
        "    for num_col in numerical_columns:\n",
        "        if num_col in SUM_COLUMNS:\n",
        "            grouped = df.groupby(col_name)[num_col].sum()\n",
        "        else:\n",
        "            grouped = df.groupby(col_name)[num_col].count()\n",
        "        spec_col[5].append([col_name,num_col])\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=grouped.index,\n",
        "            y=grouped.values,\n",
        "            text=grouped.values,\n",
        "            hovertemplate=\n",
        "            \"<b>Category:</b> %{x}<br>\" +\n",
        "            \"<b>Value:</b> %{y}<br>\" +\n",
        "            \"<extra></extra>\"\n",
        "        ))\n",
        "        fig.update_layout(\n",
        "            title=f\"{num_col} by {col_name}\",\n",
        "            xaxis_title=col_name,\n",
        "            yaxis_title=num_col\n",
        "        )\n",
        "        L_mix[j].append([])\n",
        "        L_mix[j][si].append(fig)\n",
        "        result[col_name].append(fig)\n",
        "        result[num_col].append(fig)\n",
        "        si=si+1\n",
        "    j=j+1\n",
        "\n",
        "#Pie charts>>>\n",
        "j=0\n",
        "\n",
        "for i in column_name:\n",
        "    si=0\n",
        "    if len(df[i].unique()) <= 8 and len(df[i].unique())>1:\n",
        "        spec_col[2].append([i,\"pie\"])\n",
        "        P_single.append([])\n",
        "        counts = df[i].value_counts()\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Pie(\n",
        "            labels=counts.index,\n",
        "            values=counts.values,\n",
        "            hole=0.4,\n",
        "            hovertemplate=\"<b>%{label}</b><br>Count: %{value}<extra></extra>\"\n",
        "        ))\n",
        "        fig.update_layout(\n",
        "            title=f\"Distribution of {i}\",\n",
        "            legend_title=\"Categories\"\n",
        "        )\n",
        "        P_single[j].append([])\n",
        "        P_single[j][si].append(fig)\n",
        "        pie_result[i].append(fig)\n",
        "        si=si+1\n",
        "        j=j+1\n",
        "\n",
        "j=0\n",
        "for i in X_Qualitative:\n",
        "    P_mix.append([])\n",
        "    for l in numerical_columns:\n",
        "        spec_col[6].append([i,l+\" pie\"])\n",
        "        si=0\n",
        "        grouped = df.groupby(i)[l].sum()\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Pie(\n",
        "            labels=grouped.index,\n",
        "            values=grouped.values.astype(int),\n",
        "            hole=0.4,\n",
        "            hovertemplate=\"<b>%{label}</b><br>Value: %{value}<extra></extra>\"\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"Distribution of {l} by {i}\",\n",
        "            legend_title=i\n",
        "        )\n",
        "        P_mix[j].append([])\n",
        "        P_mix[j][si].append(fig)\n",
        "        pie_result[i].append(fig)\n",
        "        pie_result[l].append(fig)\n",
        "        si=si+1\n",
        "    j=j+1\n",
        "\n",
        "# line chart\n",
        "\n",
        "def line_chart(date_col, num_col, freq=\"ME\"):\n",
        "    temp = df[[date_col, num_col]].dropna()\n",
        "\n",
        "    temp[date_col] = pd.to_datetime(\n",
        "        temp[date_col],\n",
        "        errors=\"coerce\",\n",
        "        dayfirst=True\n",
        "    )\n",
        "\n",
        "    temp = temp.dropna(subset=[date_col])\n",
        "\n",
        "    temp = (\n",
        "        temp\n",
        "        .set_index(date_col)\n",
        "        .resample(freq)[num_col]\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=temp[date_col],\n",
        "        y=temp[num_col],\n",
        "        mode=\"lines+markers\"\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"Line Chart: {num_col} over time\",\n",
        "        xaxis_title=date_col,\n",
        "        yaxis_title=num_col\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "line_charts = []\n",
        "i=0\n",
        "j=0\n",
        "for d in date_columns:\n",
        "    line_charts.append([])\n",
        "    for n in numerical_columns:\n",
        "        fig = line_chart(d, n)\n",
        "        line_charts[i].append([])\n",
        "        # print(line_charts)\n",
        "        # print(i,j)\n",
        "        line_charts[i][j].append(fig)\n",
        "        j+=1\n",
        "    i+=1\n",
        "    j=0\n",
        "\n",
        "\n",
        "#heat map\n",
        "\n",
        "def heat_map(numerical_columns):\n",
        "    corr = df[numerical_columns].corr()\n",
        "\n",
        "    fig = go.Figure(\n",
        "        data=go.Heatmap(\n",
        "            z=corr.values,\n",
        "            x=corr.columns,\n",
        "            y=corr.columns,\n",
        "            colorscale=\"Viridis\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    fig.update_layout(title=\"Correlation Heatmap\")\n",
        "    return fig\n",
        "\n",
        "heat_maps = []\n",
        "heat_maps.append([])\n",
        "fig = heat_map(numerical_columns)\n",
        "heat_maps[0].append([fig])\n",
        "\n",
        "\n",
        "# histogram charts\n",
        "\n",
        "def histogram_chart(num_col):\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Histogram(\n",
        "        x=df[num_col],\n",
        "        nbinsx=30\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"Histogram of {num_col}\",\n",
        "        xaxis_title=num_col,\n",
        "        yaxis_title=\"Count\"\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "histogram_charts = []\n",
        "i=0\n",
        "histogram_charts.append([])\n",
        "for n in numerical_columns:\n",
        "    fig = histogram_chart(n)\n",
        "    histogram_charts[0].append([])\n",
        "    histogram_charts[0][i].append(fig)\n",
        "    i+=1\n",
        "\n",
        "\n",
        "# scatter plot\n",
        "\n",
        "def scatter_plot(x_col, y_col):\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df[x_col],\n",
        "        y=df[y_col],\n",
        "        mode=\"markers\"\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"Scatter Plot: {x_col} vs {y_col}\",\n",
        "        xaxis_title=x_col,\n",
        "        yaxis_title=y_col\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "scatter_plots = []\n",
        "k=0\n",
        "l=0\n",
        "for i in range(len(numerical_columns)):\n",
        "    scatter_plots.append([])\n",
        "    for j in range(i+1,len(numerical_columns)):\n",
        "        d = numerical_columns[i]\n",
        "        n = numerical_columns[j]\n",
        "        fig = scatter_plot(d, n)\n",
        "        scatter_plots[k].append([])\n",
        "        scatter_plots[k][l].append(fig)\n",
        "        l+=1\n",
        "    k+=1\n",
        "    l=0\n",
        "\n",
        "\n",
        "# box plot\n",
        "\n",
        "def box_plot(num_col):\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Box(\n",
        "        y=df[num_col],\n",
        "        boxmean=True\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"Box Plot of {num_col}\",\n",
        "        yaxis_title=num_col\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "box_plots = []\n",
        "i=0\n",
        "box_plots.append([])\n",
        "for n in numerical_columns:\n",
        "    fig = box_plot(n)\n",
        "    box_plots[0].append([])\n",
        "    box_plots[0][i].append(fig)\n",
        "    i+=1\n",
        "\n",
        "\n",
        "# area_plots\n",
        "\n",
        "def area_chart(date_col, num_col):\n",
        "    temp = df[[date_col, num_col]].dropna()\n",
        "\n",
        "    temp[date_col] = pd.to_datetime(\n",
        "        temp[date_col],\n",
        "        errors=\"coerce\",\n",
        "        dayfirst=True\n",
        "    )\n",
        "\n",
        "    temp = temp.dropna(subset=[date_col])\n",
        "\n",
        "    temp = (\n",
        "        temp\n",
        "        .set_index(date_col)\n",
        "        .resample(\"ME\")[num_col]\n",
        "        .sum()\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=temp[date_col],\n",
        "        y=temp[num_col],\n",
        "        fill=\"tozeroy\",\n",
        "        mode=\"lines\"\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"Area Chart: {num_col}\",\n",
        "        xaxis_title=date_col,\n",
        "        yaxis_title=num_col\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "area_charts = []\n",
        "i=0\n",
        "j=0\n",
        "for d in date_columns:\n",
        "    area_charts.append([])\n",
        "    for n in numerical_columns:\n",
        "        fig = area_chart(d, n)\n",
        "        area_charts[i].append([])\n",
        "        area_charts[i][j].append(fig)\n",
        "        j+=1\n",
        "    i+=1\n",
        "    j=0\n",
        "\n",
        "\n",
        "# bubble_chart\n",
        "\n",
        "def bubble_chart(x_col, y_col, size_col):\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df[x_col],\n",
        "        y=df[y_col],\n",
        "        mode=\"markers\",\n",
        "        marker=dict(\n",
        "            size=df[size_col],\n",
        "            sizemode=\"area\",\n",
        "            sizeref=2.*max(df[size_col])/(40.**2),\n",
        "            showscale=True\n",
        "        )\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"Bubble Chart\",\n",
        "        xaxis_title=x_col,\n",
        "        yaxis_title=y_col\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "l=0\n",
        "m=0\n",
        "for i in range(len(numerical_columns)):\n",
        "    bubble_charts.append([])\n",
        "    for j in range(i + 1, len(numerical_columns)):\n",
        "        for k in range(j + 1, len(numerical_columns)):\n",
        "            x = numerical_columns[i]\n",
        "            y = numerical_columns[j]\n",
        "            size = numerical_columns[k]\n",
        "            fig=bubble_chart(x, y, size)\n",
        "            bubble_charts[l].append([])\n",
        "            bubble_charts[l][m].append(fig)\n",
        "            m+=1\n",
        "    l+=1\n",
        "    m=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = {\n",
        "    k: list({id(fig): fig for fig in v}.values())\n",
        "    for k, v in result.items()\n",
        "}\n",
        "pie_result = {\n",
        "    k: list({id(fig): fig for fig in v}.values())\n",
        "    for k, v in pie_result.items()\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_result = {k: v for k, v in result.items() if v}\n",
        "filtered_pie_result = {k: v for k, v in pie_result.items() if v}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "keys_with_values = [k for k, v in result.items() if v]\n",
        "pie_keys_with_values = [k for k, v in pie_result.items() if v]\n",
        "# print(keys_with_values)\n",
        "# print(pie_keys_with_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "i=-1\n",
        "for all in dia:\n",
        "    i+=1\n",
        "    for j in range(0,len(all)):\n",
        "        for k in range(len(all[j])):\n",
        "            for l in range(len(all[j][k])):\n",
        "                Dia_ID.append(str(i)+str(j)+str(k)+str(l))\n",
        "# print(len(dia))\n",
        "\n",
        "for i in range(len(dia)):\n",
        "    Access.append([])\n",
        "    for val in (Dia_ID):\n",
        "        if val[0]==str(i):\n",
        "            Access[i].append(val)\n",
        "# Access[:] = [x for x in Access if x]\n",
        "# print(Access)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "p1=0\n",
        "p2=0\n",
        "p3=0\n",
        "p4=0\n",
        "\n",
        "pc=2\n",
        "for i in range(len(Access[pc])):\n",
        "    if i ==0:                   \n",
        "        p1=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "        bar_check.append(Access[pc][i]) \n",
        "    elif i==1:\n",
        "        p2=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "        bar_check.append(Access[pc][i])\n",
        "    elif i==2:\n",
        "        p3=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "        bar_check.append(Access[pc][i])\n",
        "    elif i==3:\n",
        "        p4=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "        bar_check.append(Access[pc][i])\n",
        "if p1==0 or p2==0 or p3==0 or p4==0:\n",
        "    pc=6\n",
        "    if Access[pc]:\n",
        "        if p1!=0:\n",
        "            if p2!=0:\n",
        "                if p3!=0:\n",
        "                    if p4!=0:\n",
        "                        pass\n",
        "                    else:\n",
        "                        p4=dia[int(Access[pc][0][0])][int(Access[pc][0][1])][int(Access[pc][0][2])][int(Access[pc][0][3])]\n",
        "                        bar_check.append(Access[pc][0])\n",
        "                else:  \n",
        "                    for i in range(len(Access[pc])):\n",
        "                        if i ==0:\n",
        "                            p3=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "                            bar_check.append(Access[pc][i])\n",
        "                        elif i==1:\n",
        "                            p4=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "                            bar_check.append(Access[pc][i])  \n",
        "            else:\n",
        "                for i in range(len(Access[pc])):\n",
        "                    if i ==0:\n",
        "                        p2=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "                        bar_check.append(Access[pc][i])\n",
        "                    elif i==1:\n",
        "                        p3=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "                        bar_check.append(Access[pc][i])\n",
        "                    elif i==2:\n",
        "                        p4=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "                        bar_check.append(Access[pc][i])                \n",
        "        else:\n",
        "            for i in range(len(Access[pc])):\n",
        "                if i ==0:\n",
        "                    p1=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "                    bar_check.append(Access[pc][i])\n",
        "                elif i==1:\n",
        "                    p2=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "                    bar_check.append(Access[pc][i])\n",
        "                elif i==2:\n",
        "                    p3=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "                    bar_check.append(Access[pc][i])\n",
        "                elif i==3:\n",
        "                    p4=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "                    bar_check.append(Access[pc][i])\n",
        "\n",
        "a=0\n",
        "for i in range(len(Access)):\n",
        "    try:\n",
        "        a,bar_check,p1=check(i,a,bar_check,p1)\n",
        "        a,bar_check,p2=check(i,a,bar_check,p2)\n",
        "        a,bar_check,p3=check(i,a,bar_check,p3)\n",
        "        a,bar_check,p4=check(i,a,bar_check,p4)\n",
        "        if p1!=0 and p2!=0 and p3!=0 and p4!=0:\n",
        "            break\n",
        "        else:\n",
        "            a=0\n",
        "    except IndexError:\n",
        "        continue\n",
        "             \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total graphs displayed: 4\n"
          ]
        }
      ],
      "source": [
        "count=0\n",
        "for all in dia:\n",
        "    for i in range(0,len(all)):\n",
        "        for j in range(len(all[i])):\n",
        "            for k in range(len(all[i][j])):\n",
        "                # print(i,j,k)\n",
        "                # all[i][j][k].show()\n",
        "                count+=1\n",
        "print(\"Total graphs displayed:\",count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "sidechart=0\n",
        "chart1=0\n",
        "chart2=0\n",
        "for i in range(len(Access)):\n",
        "    try:\n",
        "        bar_check,sidechart=B_check(i,bar_check,sidechart)\n",
        "        bar_check,chart1=B_check(i,bar_check,chart1)\n",
        "        bar_check,chart2=B_check(i,bar_check,chart2)\n",
        "        if chart1!=0 and chart2!=0 and sidechart!=0 :\n",
        "            break\n",
        "    except IndexError:\n",
        "        continue\n",
        "if sidechart==0 or chart1==0 or chart2==0:\n",
        "    for i in Dia_ID:\n",
        "        if i not in bar_check and i not in Access[2] and i not in Access[6]:\n",
        "            if sidechart==0:\n",
        "                sidechart=dia[int(i[0])][int(i[1])][int(i[2])][int(i[3])]\n",
        "            elif chart1==0:\n",
        "                chart1=dia[int(i[0])][int(i[1])][int(i[2])][int(i[3])]\n",
        "            elif chart2==0:\n",
        "                chart2=dia[int(i[0])][int(i[1])][int(i[2])][int(i[3])]\n",
        "# sidechart.show()\n",
        "# chart1.show()\n",
        "# chart2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "a=0\n",
        "b=0\n",
        "c=0\n",
        "d=0\n",
        "A=0\n",
        "B=0\n",
        "C=0\n",
        "D=0\n",
        "\n",
        "try:\n",
        "    for i in numerical_columns:\n",
        "        if df[i].sum() not in u4 and a==0:\n",
        "            a=df[i].sum()\n",
        "            u4.append(a)\n",
        "            A=\"Total \"+i\n",
        "        elif df[i].sum() not in u4 and b==0:\n",
        "            b=df[i].sum()\n",
        "            u4.append(b)\n",
        "            B=\"Total \"+i\n",
        "        elif df[i].sum() not in u4 and c==0:\n",
        "            c=df[i].sum()\n",
        "            u4.append(c)\n",
        "            C=\"Total \"+i\n",
        "        elif df[i].sum() not in u4:\n",
        "            d=df[i].sum()\n",
        "            u4.append(d)\n",
        "            D=\"Total \"+i\n",
        "except:\n",
        "    try:\n",
        "        u4,a,b,c,d,A,B,C,D=four(alpha_columns,u4,a,b,c,d,A,B,C,D)\n",
        "    except:\n",
        "        u4,a,b,c,d,A,B,C,D=four(location_columns,u4,a,b,c,d,A,B,C,D)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
