{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vJ5lmAobxeKG"
      },
      "outputs": [],
      "source": [
        "character_columns=['name', 'department', 'departments', 'team', 'teams', 'product', 'products',\n",
        " 'region', 'regions', 'subject', 'subjects', 'class', 'school', 'schools',\n",
        " 'assignment', 'assignments', 'age group', 'age groups', 'disease', 'diseases',\n",
        " 'hospital', 'hospitals', 'city', 'cities', 'campaign', 'campaigns',\n",
        " 'platform', 'platforms', 'segment', 'segments', 'ad type', 'ad types',\n",
        " 'device', 'devices', 'app version', 'app versions', 'feature', 'features',\n",
        " 'day', 'days', 'error type', 'error types', 'country', 'countries', 'state', 'states',\n",
        " 'zone', 'zones', 'income bracket', 'income brackets', 'gender', 'genders',\n",
        " 'warehouse', 'warehouses', 'category', 'categories', 'supplier', 'suppliers',\n",
        " 'delivery route', 'delivery routes', 'shipment date', 'shipment dates',\n",
        " 'storage section', 'storage sections', 'developer', 'developers',\n",
        " 'module', 'modules', 'sprint', 'sprints', 'bug type', 'bug types',\n",
        " 'task', 'tasks', 'product type', 'product types', 'payment method',\n",
        " 'payment methods', 'customer', 'coupon', 'coupon codes', 'store branch',\n",
        " 'store branches', 'content type', 'content types', 'influencer',\n",
        " 'influencers', 'hashtag', 'hashtags', 'posting time', 'posting times',\n",
        " 'audience segment', 'audience segments', 'district', 'districts',\n",
        " 'scheme', 'schemes', 'utility', 'utility types', 'complaint type',\n",
        " 'complaint types', 'license category', 'license categories',\n",
        " 'player', 'players', 'match', 'matches', 'event', 'events',\n",
        " 'training', 'exercise', 'exercises', 'sleep day', 'meal', 'meals',\n",
        " 'expense category', 'expense categories', 'mood', 'book', 'books',\n",
        " 'course', 'courses', 'topic', 'topics', 'quiz', 'attempt', 'instructor',\n",
        " 'instructors', 'skill', 'skills', 'learning mode', 'learning modes',\n",
        " 'entry', 'entries', 'journal', 'peer', 'certificate', 'certificates']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RiAGEGJnyTug"
      },
      "outputs": [],
      "source": [
        "time_columns=['date', 'dates', 'time', 'times', 'timestamp', 'timestamps', 'datetime', 'datetimes','month', 'months',\n",
        "              'week', 'weeks', 'day', 'days',\n",
        " 'quarter', 'quarters', 'year', 'years', 'time slot', 'time slots',\n",
        " 'date', 'dates', 'season', 'seasons', 'hour', 'hours',\n",
        " 'posting time', 'posting times', 'training day', 'sleep day',\n",
        " 'shipment date', 'shipment dates','qtr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IybPX-9JU6Td"
      },
      "outputs": [],
      "source": [
        "location_terms = {\n",
        "    \"country\": [\n",
        "        \"country\", \"nation\", \"country_name\", \"nationality\", \"sovereign_state\",\n",
        "        \"land\", \"homeland\", \"country_code\", \"iso_country\", \"nation_name\",\n",
        "        \"odname\", \"dev\", \"world\", \"continent\", \"subcontinent\", \"subregion\",\n",
        "        \"member_state\", \"member_country\", \"state_party\"\n",
        "    ],\n",
        "    \"city\": [\n",
        "        \"city\", \"town\", \"municipality\", \"metro\", \"metropolis\", \"urban_area\",\n",
        "        \"city_name\", \"township\", \"borough\", \"capital\", \"village\", \"urban\",\n",
        "        \"metro_area\", \"conurbation\", \"settlement\", \"locality_name\"\n",
        "    ],\n",
        "    \"state\": [\n",
        "        \"state\", \"province\", \"region\", \"territory\", \"governorate\", \"prefecture\",\n",
        "        \"division\", \"county\", \"oblast\", \"subdivision\", \"federal_state\", \"administrative_area\",\n",
        "        \"state_name\", \"province_name\", \"region_name\", \"territory_name\", \"governorate_name\",\n",
        "        \"prefecture_name\", \"division_name\", \"county_name\", \"oblast_name\",\n",
        "        \"state_code\", \"province_code\", \"region_code\", \"territory_code\", \"governorate_code\",\n",
        "        \"prefecture_code\", \"division_code\", \"county_code\", \"oblast_code\",\n",
        "        \"state_id\", \"province_id\", \"region_id\", \"territory_id\", \"governorate_id\",\n",
        "        \"prefecture_id\", \"division_id\", \"county_id\", \"oblast_id\",\n",
        "        \"state_abbr\", \"province_abbr\", \"region_abbr\", \"territory_abbr\", \"governorate_abbr\",\n",
        "        \"prefecture_abbr\", \"division_abbr\", \"county_abbr\", \"oblast_abbr\",\n",
        "        \"state_iso\", \"province_iso\", \"region_iso\", \"territory_iso\", \"governorate_iso\",\n",
        "        \"prefecture_iso\", \"division_iso\", \"county_iso\", \"oblast_iso\",\n",
        "        \"reg\", \"reg_name\", \"reg_code\", \"reg_abbr\", \"reg_iso\", \"regname\",\n",
        "        \"statehood\", \"admin_region\", \"admin_division\", \"state_entity\"\n",
        "    ],\n",
        "    \"area\": [\n",
        "        \"area\", \"district\", \"locality\", \"zone\", \"subzone\", \"sector\",\n",
        "        \"ward\", \"neighborhood\", \"region_area\", \"block\", \"circle\", \"areaname\",\n",
        "        \"subdistrict\", \"tehsil\", \"taluka\", \"parish\", \"commune\", \"borough_area\"\n",
        "    ],\n",
        "    \"postal\": [\n",
        "        \"postal\",\"postalcode\", \"postal_code\", \"zipcode\", \"zip\", \"pin\", \"pincode\",\n",
        "        \"post_code\", \"mail_code\", \"zip_code\", \"postal_number\", \"postcode\",\n",
        "        \"delivery_code\", \"sorting_code\"\n",
        "    ],\n",
        "    \"address\": [\n",
        "        \"address\", \"street\", \"street_address\", \"road\", \"lane\", \"avenue\", \"drive\",\n",
        "        \"colony\", \"apartment\", \"flat\", \"building\", \"house_number\", \"location\",\n",
        "        \"residence\", \"unit\", \"plot\", \"lot\", \"address_line\"\n",
        "    ],\n",
        "    \"coordinates\": [\n",
        "        \"latitude\", \"lat\", \"longitude\", \"lon\", \"lng\", \"geo\",\n",
        "        \"geo_location\", \"coordinates\", \"x_coord\", \"y_coord\", \"geocode\",\n",
        "        \"latlon\", \"longlat\", \"gps\", \"spatial\", \"geom\"\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U1Z3d9iQyoOy"
      },
      "outputs": [],
      "source": [
        "Numerical_columns=['id','sales', 'revenue', 'growth', 'expense', 'expenses', 'count', 'counts',\n",
        " 'score', 'scores', 'rating', 'ratings', 'completion', 'attendance',\n",
        " 'population', 'income', 'performance', 'progress', 'conversion',\n",
        " 'clicks', 'reach', 'usage', 'crashes', 'crash', 'frequency',\n",
        " 'GDP', 'engagement', 'vaccinations', 'mortality', 'patients',\n",
        " 'cases', 'admissions', 'footfall', 'impressions', 'views',\n",
        " 'capacity', 'volume', 'stats', 'mastery', 'attempts',\n",
        " 'coverage', 'distribution', 'amount', 'percent', 'percentage',\n",
        " 'rate', 'rates', 'spent', 'spend', 'return', 'budget', 'budgets',\n",
        " 'redemption', 'allocation', 'satisfaction', 'like', 'likes',\n",
        " 'share', 'shares', 'followers', 'follower', 'reach', 'ROI',\n",
        " 'usage', 'value', 'values', 'lead', 'leads', 'crashes',\n",
        " 'api calls', 'downloads', 'temperature', 'transactions',\n",
        " 'visits', 'visitors', 'literacy', 'energy', 'traffic',\n",
        " 'restock', 'delivery', 'orders', 'stock', 'quantity',\n",
        " 'damage', 'line', 'code', 'bugs', 'fixed', 'commits',\n",
        " 'test coverage', 'placed', 'purchases', 'calories',\n",
        " 'calorie', 'burned', 'speed', 'ranking', 'point', 'points',\n",
        " 'goals', 'score', 'completed', 'attempts', 'correct',\n",
        " 'answer', 'difficulty', 'duration', 'productivity',\n",
        " 'usage', 'conversion', 'engagement', 'impressions','avg','average']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tLqga8W8cyQH"
      },
      "outputs": [],
      "source": [
        "Contact = [\"phone\",\"phone_number\",\"mobile\",\"mobile_number\",\"contact\",\"contact_number\",\n",
        "           \"telephone\",\"telephone_number\",\"cell\",\"cell_number\",\"phone_no\",\"mobile_no\",\n",
        "           \"contact_no\",\"tel_no\",\"primary_phone\",\"secondary_phone\",\"work_phone\",\"home_phone\",\n",
        "           \"office_phone\",\"personal_phone\",\"emergency_contact_number\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "puhZMBATReGd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "from os import replace\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv=[\"Breast_cancer_data.csv\",\"Canada.csv\",\"categories.csv\",\"Chocolate Sales.csv\",\"Diwali Sales Data.csv\",\"employees.csv\",\"full_order_details.csv\",\"Most Runs - 2022.csv\",\"order_details.csv\",\"Practicle 7 tableau_project_dataset (1).csv\",\"products.csv\",\"remain.csv\",\"sales_data_sample.csv\",\"Sales_Data_Big.csv\",\"Sample - Superstore.csv\",\"student_performance_dataset.csv\",\"superstore_sales.csv\",\"suppliers.csv\",\"test_sheet.csv\",\"try.csv\",\"x_y_axis_terms.csv\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "qRvNGasXuGy9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "order_details.csv\n"
          ]
        }
      ],
      "source": [
        "i=8\n",
        "df=pd.read_csv(csv[i],encoding='unicode_escape')\n",
        "# df=pd.read_excel(\"Tableau Joins File.xlsx\")\n",
        "# df=pd.read_json(\"try.json\")\n",
        "print(csv[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "5s8Bl7NNKVvi"
      },
      "outputs": [],
      "source": [
        "total_column_count=0\n",
        "total_row_count=0\n",
        "column_name=[]\n",
        "null_columns=[]\n",
        "droped_column=[]\n",
        "numerical_columns=[]\n",
        "phone_number_column=[]\n",
        "alpha_columns=[]\n",
        "date_columns=[]\n",
        "location_columns=[]\n",
        "country=[]\n",
        "city=[]\n",
        "state=[]\n",
        "postal_code=[]\n",
        "area=[]\n",
        "address=[]\n",
        "coordinates=[]\n",
        "new_cols=[]\n",
        "shape=[]\n",
        "org_shape=df.shape\n",
        "summary=[\"org_shape\",\"shape\",\"total_column_count\",\"total_row_count\",\"column_name\",\n",
        "         \"null_columns\",\"droped_column\",\"numerical_columns\",\"alpha_columns\",\n",
        "         \"date_columns\",\"location_columns\",\"phone_number_column\",\"new_cols\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [],
      "source": [
        "shape=list(df.shape)\n",
        "df.columns = df.columns.str.strip().str.replace(r'\\s+', '_', regex=True).str.lower()\n",
        "df.drop_duplicates(inplace=True)\n",
        "column_name=df.columns\n",
        "null_columns=df.columns[df.isnull().any()].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvZxO7jKslbT",
        "outputId": "6402c5bb-92d2-4bd2-ebc6-015118a19099"
      },
      "outputs": [],
      "source": [
        "droped_column=[]\n",
        "for i in null_columns:\n",
        "  if (df[i].count()<= (len(df)//3)):\n",
        "    droped_column.append(i)\n",
        "    df.drop(columns=[i],inplace=True)\n",
        "total_column_count=len(df.columns)\n",
        "total_row_count=len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C1hKI5-cH2H",
        "outputId": "5da97f5a-2e68-490d-9c8d-fb9f2a355a31"
      },
      "outputs": [],
      "source": [
        "numerical_columns=df.select_dtypes(include=\"number\").columns.tolist()\n",
        "alpha_columns=df.select_dtypes(include=['object','string']).columns.tolist()\n",
        "date_columns=df.select_dtypes(include=['datetime']).columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "4XVB_KKZoTko"
      },
      "outputs": [],
      "source": [
        "#check date in numerical\n",
        "\n",
        "from os import replace\n",
        "for check_date in numerical_columns:\n",
        "  check=check_date.translate(str.maketrans(\"_-/\",\"   \")).split()\n",
        "  for i in check[:]:\n",
        "    for j in time_columns:\n",
        "      if i==j:\n",
        "        if check_date not in date_columns:\n",
        "          date_columns.append(check_date)\n",
        "        if check_date not in time_columns:\n",
        "          time_columns.append(check_date)\n",
        "          break\n",
        "        else:\n",
        "          break\n",
        "for r in date_columns:\n",
        "  if r in numerical_columns:\n",
        "    numerical_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "collapsed": true,
        "id": "7Ai9t1ejdg0X"
      },
      "outputs": [],
      "source": [
        "#check aplha column to dataset\n",
        "\n",
        "for j in alpha_columns:\n",
        "  for i in character_columns:\n",
        "    if j==i:\n",
        "      flag=0\n",
        "      break\n",
        "    flag=1\n",
        "  if flag==1:\n",
        "    character_columns.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "w-tw2uTUS0qu"
      },
      "outputs": [],
      "source": [
        "#check date column from dataset\n",
        "\n",
        "for i in alpha_columns:\n",
        "  for j in time_columns:\n",
        "    if i==j:\n",
        "      if i not in date_columns:\n",
        "        date_columns.append(i)\n",
        "      break\n",
        "for r in date_columns:\n",
        "  if r in alpha_columns:\n",
        "    alpha_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "OmLAvCfLT_Wk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_13412\\1229678830.py:9: FutureWarning:\n",
            "\n",
            "errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#check numerical column from dataset\n",
        "\n",
        "for i in alpha_columns:\n",
        "  for j in Numerical_columns:\n",
        "    if i==j:\n",
        "      if i not in numerical_columns:\n",
        "        try:\n",
        "          df[i]=df[i].astype(str).str.replace(r\"[,%$]\", \"\", regex=True).str.strip()\n",
        "          df[i]=pd.to_numeric(df[i],errors='ignore')\n",
        "        finally:\n",
        "          numerical_columns.append(i)\n",
        "      break\n",
        "for r in numerical_columns:\n",
        "  if r in alpha_columns:\n",
        "    alpha_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "id": "-8VS5FJ-o2lp"
      },
      "outputs": [],
      "source": [
        "#numerical detector___________check later\n",
        "\n",
        "for i in alpha_columns:\n",
        "    for j in Numerical_columns:\n",
        "        pattern = (\n",
        "            r'(^' + re.escape(j) + r'$|' +\n",
        "            r'^' + re.escape(j) + r'([_\\-\\s]|$)|' +\n",
        "            r'([_\\-\\s]|^)' + re.escape(j) + r'$|' +\n",
        "            r'.*'+re.escape(j)+r'.*'\n",
        "            r')'\n",
        "        )\n",
        "        if re.search(pattern, i, re.IGNORECASE):\n",
        "            if i not in numerical_columns:\n",
        "              v=df.loc[0,i]\n",
        "              val=\"1234567890%.$-*+\"\n",
        "              nflag=0\n",
        "              for fst in v:\n",
        "                if fst in val:\n",
        "                  nflag=nflag+1\n",
        "              if nflag==(len(v)):\n",
        "                df[i]=(df[i]\n",
        "                  .astype(str)\n",
        "                  .str.replace(r\"[,_\\-%\\$\\*]\", \"\", regex=True)\n",
        "                  .str.strip()\n",
        "                  )\n",
        "                df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "                numerical_columns.append(i)\n",
        "              break\n",
        "\n",
        "for r in numerical_columns:\n",
        "    if r in alpha_columns:\n",
        "        alpha_columns.remove(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "id": "nYFAz6SrskGV"
      },
      "outputs": [],
      "source": [
        "#date time detector\n",
        "\n",
        "for i in alpha_columns:\n",
        "    for j in time_columns:\n",
        "        pattern = (\n",
        "            r'(^' + re.escape(j) + r'$|' +\n",
        "            r'^' + re.escape(j) + r'([_\\-\\s]|$)|' +\n",
        "            r'([_\\-\\s]|^)' + re.escape(j) + r'$|' +\n",
        "            r'.*' + re.escape(j) + r'.*'\n",
        "            r')'\n",
        "        )\n",
        "        if re.search(pattern, i, re.IGNORECASE):\n",
        "            if i not in date_columns:\n",
        "                date_columns.append(i)\n",
        "            break\n",
        "\n",
        "def detect_and_convert_date(col,fmt,check):\n",
        "    col = col.astype(str).str.strip()\n",
        "    if col.str.fullmatch(r\"\\d{1,2}\").all():\n",
        "        return col.astype(int), None, None\n",
        "    if col.str.fullmatch(r\"\\d{2,4}\").all():\n",
        "        return col.astype(int), None, None\n",
        "    if check[0:4].isdigit():\n",
        "        fmt=\"%Y-%m-%d\"\n",
        "    if len(check)>10:\n",
        "        fmt=\"%m-%d-%Y %H:%M:%S.%f\"\n",
        "    parsed = pd.to_datetime(col, errors=\"coerce\", format=fmt)\n",
        "    if parsed.isnull().all():\n",
        "        fmt=\"%m-%d-%Y\"\n",
        "        parsed = pd.to_datetime(col, errors=\"coerce\")\n",
        "    month_col = parsed.dt.month\n",
        "    year_col = parsed.dt.year\n",
        "    return parsed.dt.strftime(fmt), month_col,year_col\n",
        "for r in date_columns:\n",
        "    df[r]=df[r].replace(\"/\",\"-\")\n",
        "    fmt=\"%d-%m-%Y\"\n",
        "    check = df.loc[0,r]\n",
        "    check = str(check).strip()\n",
        "    try:\n",
        "        if (check[3] in ['-','/'] and check[4].isalpha()) or (check[3].lower().isalpha()):\n",
        "            flag=2\n",
        "            df[r]=df[r].astype(str).str.lower().str.strip()\n",
        "            df[r]=df[r].replace({\"jan\":\"01\",\"feb\":\"02\",\"mar\":\"03\",\"apr\":\"04\",\"may\":\"05\",\"jun\":\"06\",\n",
        "                             \"jul\":\"07\",\"aug\":\"08\",\"sep\":\"09\",\"oct\":\"10\",\"nov\":\"11\",\"dec\":\"12\",\"january\":\"01\",\n",
        "                             \"february\":\"02\",\"march\":\"03\",\"april\":\"04\",\"june\":\"06\",\n",
        "                             \"july\":\"07\",\"august\":\"08\",\"september\":\"09\",\"october\":\"10\",\n",
        "                             \"november\":\"11\",\"december\":\"12\"},\n",
        "                            regex=True)\n",
        "            df[r] = pd.to_datetime(df[r],errors=\"coerce\",format=\"%d-%m-%y\").dt.strftime(\"%d-%m-%y\")\n",
        "            if len(df.loc[0,r])==8:\n",
        "                fmt=\"%d-%m-%y\"\n",
        "    except IndexError:\n",
        "        fmt=\"%d-%m-%Y\"\n",
        "    finally:\n",
        "        df[r], month,year = detect_and_convert_date(df[r],fmt,check)\n",
        "        if month is not None:\n",
        "            df[r + \"_month\"] = month\n",
        "            new_cols.append(r + \"_month\")\n",
        "        \n",
        "        if year is not None:\n",
        "            df[r + \"_year\"] = year\n",
        "            new_cols.append(r + \"_year\")\n",
        "    \n",
        "        if r in alpha_columns:\n",
        "            alpha_columns.remove(r)\n",
        "for new in new_cols:\n",
        "    date_columns.append(new)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter duplicate date columns\n",
        "\n",
        "r=[]\n",
        "for i in new_cols:\n",
        "    for j in date_columns:\n",
        "        count=len(df)-1\n",
        "        check=0\n",
        "        for k in range(0,len(df)-1):\n",
        "            if df.loc[k,i]==df.loc[k,j] and i!=j:\n",
        "                check=check+1\n",
        "            else:\n",
        "                break\n",
        "        if count==check:\n",
        "            r.append(i)\n",
        "            \n",
        "for i in r:\n",
        "    date_columns.remove(i)\n",
        "    df.drop(columns=[i],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [],
      "source": [
        "column_name=df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "ChCVWe_pZTVc"
      },
      "outputs": [],
      "source": [
        "#Location detector\n",
        "\n",
        "for i in location_terms:\n",
        "  for j in range(len(location_terms[i])):\n",
        "    for k in alpha_columns:\n",
        "      if k==location_terms[i][j]:\n",
        "        if k not in location_columns:\n",
        "          location_columns.append(k)\n",
        "          if i==\"country\":\n",
        "            country.append(k)\n",
        "          elif i==\"city\":\n",
        "            city.append(k)\n",
        "          elif i==\"state\":\n",
        "            state.append(k)\n",
        "          elif i==\"area\":\n",
        "            area.append(k)\n",
        "          elif i==\"postal\":\n",
        "            postal_code.append(k)\n",
        "          elif i==\"address\":\n",
        "            address.append(k)\n",
        "          elif i==\"coordinates\":\n",
        "            coordinates.append(k)\n",
        "    for n in numerical_columns:\n",
        "      if n==location_terms[i][j]:\n",
        "        if n not in location_columns:\n",
        "          location_columns.append(n)\n",
        "          if i==\"postal\":\n",
        "            postal_code.append(n)\n",
        "for r in location_columns:\n",
        "  if r in alpha_columns:\n",
        "    alpha_columns.remove(r)\n",
        "for rn in location_columns:\n",
        "  if rn in numerical_columns:\n",
        "    numerical_columns.remove(rn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jpxLyQ3cKfW",
        "outputId": "076ccdc1-f8ab-46b8-cb32-ebc94d6fffbb"
      },
      "outputs": [],
      "source": [
        "#non alphabetical pushed to numerical\n",
        "\n",
        "for i in alpha_columns:\n",
        "  flag=0\n",
        "  add=0\n",
        "  sub=0\n",
        "  nct=0\n",
        "  fstvl=0\n",
        "  lstvl=0\n",
        "  special=0\n",
        "  value=df.loc[0,i]\n",
        "  val=\"1234567890\"\n",
        "  alpha = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "  Alpha = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "  if (len(value)==1) and ((value in alpha) or (value in Alpha)):\n",
        "    continue\n",
        "    if isinstance(value, str):\n",
        "      val=\"1234567890\"\n",
        "      vald=\"1234567890.\"\n",
        "      value=value.replace(\",\",\"\").strip()\n",
        "      for tr in range(len(value)):\n",
        "        if (value[tr] not in val) and (value[tr]==value[0]):\n",
        "          fstvl=1\n",
        "        elif (value[tr] not in val) and (value[tr]==value[-1]):\n",
        "          lstvl=1\n",
        "        elif (value[tr] in val):\n",
        "          flag=flag+1\n",
        "        elif (value[tr]==\".\"):\n",
        "          flag=flag+1\n",
        "          special=special+1\n",
        "    if (fstvl==1) and ((len(value)-1)==flag):\n",
        "      for cv in range(len(df[i])):\n",
        "        val_str = str(df.loc[cv, i])\n",
        "        for see in val_str:\n",
        "          if (sub==0) and (see==\"-\"):\n",
        "            sub=1\n",
        "          elif see not in vald:\n",
        "            val_str = val_str.replace(see, \"\")\n",
        "        df.loc[cv, i] = val_str\n",
        "      df[i]=(df[i]\n",
        "            .astype(str)\n",
        "            .str.replace(\",\",\"\",regex=False)\n",
        "            .str.strip()\n",
        "            )\n",
        "      df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "      numerical_columns.append(i)\n",
        "    elif (lstvl==1) and ((len(value)-1)==flag):\n",
        "      for cv in range(len(df[i])):\n",
        "        val_str = str(df.loc[cv, i])\n",
        "        for see in val_str:\n",
        "          if (sub==0) and (see==\"-\"):\n",
        "            sub=1\n",
        "          elif see not in vald:\n",
        "            val_str = val_str.replace(see, \"\")\n",
        "        df.loc[cv, i] = val_str\n",
        "      df[i]=(df[i]\n",
        "            .astype(str)\n",
        "            .str.replace(\",\",\"\",regex=False)\n",
        "            .str.strip()\n",
        "            )\n",
        "      df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "      numerical_columns.append(i)\n",
        "    elif (special==1) and ((len(value))==flag):\n",
        "      for cv in range(len(df[i])):\n",
        "        val_str = str(df.loc[cv, i])\n",
        "        for see in val_str:\n",
        "          if (sub==0) and (see==\"-\"):\n",
        "            sub=1\n",
        "          elif see not in vald:\n",
        "            val_str = val_str.replace(see, \"\")\n",
        "        df.loc[cv, i] = val_str\n",
        "      df[i]=(df[i]\n",
        "            .astype(str)\n",
        "            .str.replace(\",\",\"\",regex=False)\n",
        "            .str.strip()\n",
        "            )\n",
        "      df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "      numerical_columns.append(i)\n",
        "    elif (special==0) and ((len(value))==flag) and (lstvl==0) and (fstvl==0):\n",
        "      for cv in range(len(df[i])):\n",
        "        val_str = str(df.loc[cv, i])\n",
        "        for see in val_str:\n",
        "          if (sub==0) and (see==\"-\"):\n",
        "            sub=1\n",
        "          elif see not in vald:\n",
        "            val_str = val_str.replace(see, \"\")\n",
        "        df.loc[cv, i] = val_str\n",
        "      df[i]=(df[i]\n",
        "            .astype(str)\n",
        "            .str.replace(\",\",\"\",regex=False)\n",
        "            .str.strip()\n",
        "            )\n",
        "      df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "      numerical_columns.append(i)\n",
        "  else:\n",
        "    value=str(value).strip()\n",
        "    if value.isdigit():\n",
        "      df[i]=df[i].astype(str).str.strip()\n",
        "      df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "      numerical_columns.append(i)\n",
        "    elif (isinstance(value,str)):\n",
        "      for cv in value:\n",
        "        if cv in val:\n",
        "          nct=nct+1\n",
        "      if len(value)==nct:\n",
        "        df[i]=(df[i]\n",
        "            .astype(str)\n",
        "            .str.replace(r\"[,_\\-%\\$\\*]\", \"\", regex=True)\n",
        "            .str.strip()\n",
        "            )\n",
        "        df[i]=pd.to_numeric(df[i],errors=\"coerce\")\n",
        "        numerical_columns.append(i)\n",
        "\n",
        "for r in numerical_columns:\n",
        "  if r in alpha_columns:\n",
        "    alpha_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "L635K18PYyYR"
      },
      "outputs": [],
      "source": [
        "#non numerical pushed to alphabetical\n",
        "\n",
        "for i in numerical_columns:\n",
        "  flag=0\n",
        "  add=0\n",
        "  sub=0\n",
        "  value = df.loc[0, i]\n",
        "  if isinstance(value, str):\n",
        "    val=\"1234567890\"\n",
        "    vald=\"1234567890.\"\n",
        "    alpha=\"abcdefghijklmnopqrstuvwxyz\"\n",
        "    Alpha=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "    value=value.replace(\",\",\"\").strip()\n",
        "    for tr in range(1,len(value)):\n",
        "      if (isinstance(value[0],str) and (value[tr] in val) ) or ((value[0] in val) and (value[tr] in val)) or ((value[tr-1] in val) and (isinstance(value[-1],str))):\n",
        "        flag=1\n",
        "      elif (value[tr] == \".\"):\n",
        "        flag=1\n",
        "      else:\n",
        "        add=add+1\n",
        "  flag=flag+add\n",
        "  if (flag==1) and (((value[0] not in alpha) and (value[0] not in Alpha)) and ((value[-1] not in alpha) and (value[-1] not in Alpha))):\n",
        "    if len(df[i])<=100:\n",
        "        check_len=len(df[i])\n",
        "    else:\n",
        "        check_len=60\n",
        "    n=np.random.randint(1, len(df[i])//3)\n",
        "    for cv in range(n,check_len):\n",
        "      val_str = str(df.loc[cv, i])\n",
        "      for see in val_str:\n",
        "        if (sub==0) and (see==\"-\"):\n",
        "          sub=1\n",
        "        elif (see not in vald):\n",
        "          val_str = val_str.replace(see, \"\")\n",
        "      df.loc[cv, i] = val_str\n",
        "    df[i] = (\n",
        "    df[i]\n",
        "    .astype(str)\n",
        "    .str.replace(\",\", \"\", regex=False)\n",
        "    .str.strip())\n",
        "    df[i] = pd.to_numeric(df[i], errors=\"coerce\")\n",
        "  elif (flag>1) or ((flag==1) and (((value[0] in alpha) or (value[0] in Alpha)) or ((value[-1] in alpha) or (value[-1] in Alpha)))):\n",
        "    alpha_columns.append(i)\n",
        "for r in alpha_columns:\n",
        "  if r in numerical_columns:\n",
        "    numerical_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "nOvJ_WP8cDZc"
      },
      "outputs": [],
      "source": [
        "#phone number detector from numerical column\n",
        "for i in numerical_columns:\n",
        "  if i in Contact:\n",
        "    phone_number_column.append(i)\n",
        "    numerical_columns.remove(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "Qt_PhwwyGTxT"
      },
      "outputs": [],
      "source": [
        "#filter alpha columns\n",
        "for r in alpha_columns:\n",
        "  if r in numerical_columns:\n",
        "    alpha_columns.remove(r)\n",
        "  elif r in date_columns:\n",
        "    alpha_columns.remove(r)\n",
        "  elif r in location_columns:\n",
        "    alpha_columns.remove(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "LdqX0DBSSet6"
      },
      "outputs": [],
      "source": [
        "#formatting alpha columns\n",
        "for i in alpha_columns:\n",
        "  df[i]=df[i].str.strip()\n",
        "  df[i]=df[i].str.title()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "shape=list(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in alpha_columns:\n",
        "    df[i]=df[i].str.lower()\n",
        "    val=df.loc[0,i]\n",
        "    if (val==\"yes\") or (val==\"no\") or (val==\"y\") or (val==\"n\"):\n",
        "        df[i]=df[i].replace({\"yes\":\"Yes\",\"no\":\"No\",\"y\":\"Yes\",\"n\":\"No\"})\n",
        "    elif (val==\"true\") or (val==\"false\"):\n",
        "        df[i]=df[i].replace({\"true\":\"True\",\"false\":\"False\"})\n",
        "    elif (val==\"m\") or (val==\"f\"):\n",
        "        df[i].replace({\"m\":\"Male\",\"f\":\"Female\"},inplace=True)\n",
        "    df[i]=df[i].str.title()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in alpha_columns:\n",
        "    df[i]=df[i].fillna(\"Unknown\")\n",
        "for i in numerical_columns:\n",
        "    df[i]=df[i].fillna(df[i].median())\n",
        "for i in location_columns:\n",
        "    df[i]=df[i].fillna(\"Unknown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "org_shape:-\n",
            "(518, 4)\n",
            "\n",
            "shape:-\n",
            "[518, 4]\n",
            "\n",
            "total_column_count:-\n",
            "4\n",
            "\n",
            "total_row_count:-\n",
            "518\n",
            "\n",
            "column_name:-\n",
            "Index(['orderdetailid', 'orderid', 'product', 'quantity'], dtype='object')\n",
            "\n",
            "null_columns:-\n",
            "[]\n",
            "\n",
            "droped_column:-\n",
            "[]\n",
            "\n",
            "numerical_columns:-\n",
            "['quantity', 'orderdetailid', 'orderid', 'product']\n",
            "\n",
            "alpha_columns:-\n",
            "[]\n",
            "\n",
            "date_columns:-\n",
            "[]\n",
            "\n",
            "location_columns:-\n",
            "[]\n",
            "\n",
            "phone_number_column:-\n",
            "[]\n",
            "\n",
            "new_cols:-\n",
            "[]\n",
            "\n",
            "orderdetailid\n",
            "count    518.000000\n",
            "mean     259.500000\n",
            "std      149.677988\n",
            "min        1.000000\n",
            "25%      130.250000\n",
            "50%      259.500000\n",
            "75%      388.750000\n",
            "max      518.000000\n",
            "Name: orderdetailid, dtype: float64\n",
            "\n",
            "orderid\n",
            "count      518.000000\n",
            "mean     10344.791506\n",
            "std         56.461272\n",
            "min      10248.000000\n",
            "25%      10296.000000\n",
            "50%      10344.000000\n",
            "75%      10393.000000\n",
            "max      10443.000000\n",
            "Name: orderid, dtype: float64\n",
            "\n",
            "product\n",
            "count    518.000000\n",
            "mean      42.055985\n",
            "std       21.992322\n",
            "min        1.000000\n",
            "25%       24.000000\n",
            "50%       41.000000\n",
            "75%       61.000000\n",
            "max       77.000000\n",
            "Name: product, dtype: float64\n",
            "\n",
            "quantity\n",
            "count    518.000000\n",
            "mean      24.600386\n",
            "std       18.376899\n",
            "min        1.000000\n",
            "25%       10.000000\n",
            "50%       20.000000\n",
            "75%       32.750000\n",
            "max      120.000000\n",
            "Name: quantity, dtype: float64\n",
            "\n",
            "   orderdetailid  orderid  product  quantity\n",
            "0              1    10248       11        12\n",
            "1              2    10248       42        10\n",
            "2              3    10248       72         5\n",
            "3              4    10249       14         9\n",
            "4              5    10249       51        40\n",
            "     orderdetailid  orderid  product  quantity\n",
            "513            514    10442       11        30\n",
            "514            515    10442       54        80\n",
            "515            516    10442       66        60\n",
            "516            517    10443       11         6\n",
            "517            518    10443       28        12\n"
          ]
        }
      ],
      "source": [
        "for i in summary:\n",
        "    print(f\"{i}:-\\n{eval(i)}\\n\")\n",
        "for i in df.columns:\n",
        "    print(f\"{i}\\n{df[i].describe()}\\n\")\n",
        "print(df.head())\n",
        "print(df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [],
      "source": [
        "#graph col:-\n",
        "X_Qualitative=[]\n",
        "X_Quantitative=[]\n",
        "X_Location=[]\n",
        "X_Time=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "for i in column_name:\n",
        "    a=len(df[i].unique())\n",
        "    if a<=15 :\n",
        "        if i in alpha_columns:\n",
        "            X_Qualitative.append(i)\n",
        "        elif i in numerical_columns:\n",
        "            X_Quantitative.append(i)\n",
        "        elif i in date_columns:\n",
        "            X_Time.append(i)\n",
        "print(X_Qualitative)\n",
        "print(X_Quantitative)\n",
        "print(X_Time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [],
      "source": [
        "single=[]\n",
        "N_single=[]\n",
        "P_single=[]\n",
        "mix=[]\n",
        "N_mix=[]\n",
        "L_mix=[]\n",
        "P_mix=[]\n",
        "dia=[single,N_single,P_single,mix,N_mix,L_mix,P_mix]\n",
        "Dia_ID=[]\n",
        "Access=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar charts>>>\n",
        "j=0\n",
        "k=0\n",
        "\n",
        "for col_index, col_name in enumerate(X_Qualitative):\n",
        "    unique_vals = df[col_name].unique()\n",
        "    if len(unique_vals) < 3 or len(unique_vals)>15:\n",
        "        single.append([])\n",
        "        grouped = df.groupby(col_name)[numerical_columns].sum()\n",
        "        i=0\n",
        "        for category in unique_vals:\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=numerical_columns,\n",
        "                y=grouped.loc[category],\n",
        "                text=grouped.loc[category],\n",
        "                hovertemplate=\n",
        "                \"<b>Column:</b> %{x}<br>\" +\n",
        "                \"<b>Value:</b> %{y}<br>\" +\n",
        "                \"<extra></extra>\"\n",
        "            ))\n",
        "            fig.update_layout(\n",
        "                title=f\"{category} summary for column {col_name}\",\n",
        "                xaxis_title=\"Numerical Columns\",\n",
        "                yaxis_title=\"Sum\",\n",
        "                hoverlabel=dict(bgcolor=\"white\")\n",
        "            )\n",
        "            single[j].append([])\n",
        "            single[j][i].append(fig)\n",
        "            i=i+1\n",
        "        j=j+1\n",
        "    else:\n",
        "        mix.append([])\n",
        "        si=0\n",
        "        for num_col in numerical_columns:\n",
        "            grouped = df.groupby(col_name)[num_col].sum()\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=grouped.index,\n",
        "                y=grouped.values,\n",
        "                text=grouped.values,\n",
        "                hovertemplate=\n",
        "                \"<b>Category:</b> %{x}<br>\" +\n",
        "                \"<b>Value:</b> %{y}<br>\" +\n",
        "                \"<extra></extra>\"\n",
        "            ))\n",
        "            fig.update_layout(\n",
        "                title=f\"{num_col} by {col_name}\",\n",
        "                xaxis_title=col_name,\n",
        "                yaxis_title=num_col\n",
        "            )\n",
        "            mix[k].append([])\n",
        "            mix[k][si].append(fig)\n",
        "            si=si+1\n",
        "        k=k+1\n",
        "\n",
        "j=0\n",
        "k=0\n",
        "\n",
        "\n",
        "for col_index, col_name in enumerate(X_Quantitative):\n",
        "    unique_vals = df[col_name].unique()\n",
        "    if len(unique_vals) < 3:\n",
        "        N_single.append([])\n",
        "        grouped = df.groupby(col_name)[numerical_columns].sum()\n",
        "        i=0\n",
        "        for category in unique_vals:\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=numerical_columns,\n",
        "                y=grouped.loc[category],\n",
        "                text=grouped.loc[category],\n",
        "                hovertemplate=\n",
        "                \"<b>Column:</b> %{x}<br>\" +\n",
        "                \"<b>Value:</b> %{y}<br>\" +\n",
        "                \"<extra></extra>\"\n",
        "            ))\n",
        "            fig.update_layout(\n",
        "                title=f\"{category} summary for column {col_name}\",\n",
        "                xaxis_title=\"Numerical Columns\",\n",
        "                yaxis_title=\"Sum\",\n",
        "                hoverlabel=dict(bgcolor=\"white\")\n",
        "            )\n",
        "            N_single[j].append([])\n",
        "            N_single[j][i].append(fig)\n",
        "            i=i+1\n",
        "        j=j+1\n",
        "            \n",
        "\n",
        "    else:\n",
        "        N_mix.append([])\n",
        "        si=0\n",
        "        for num_col in numerical_columns:\n",
        "            grouped = df.groupby(col_name)[num_col].sum()\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=grouped.index,\n",
        "                y=grouped.values,\n",
        "                text=grouped.values,\n",
        "                hovertemplate=\n",
        "                \"<b>Category:</b> %{x}<br>\" +\n",
        "                \"<b>Value:</b> %{y}<br>\" +\n",
        "                \"<extra></extra>\"\n",
        "            ))\n",
        "            fig.update_layout(\n",
        "                title=f\"{num_col} by {col_name}\",\n",
        "                xaxis_title=col_name,\n",
        "                yaxis_title=num_col\n",
        "            )\n",
        "            N_mix[k].append([])\n",
        "            N_mix[k][si].append(fig)\n",
        "            si=si+1\n",
        "        k=k+1\n",
        "\n",
        "j=0\n",
        "\n",
        "for col_index, col_name in enumerate(location_columns):\n",
        "    L_mix.append([])\n",
        "    si=0\n",
        "    for num_col in numerical_columns:\n",
        "        grouped = df.groupby(col_name)[num_col].sum()\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=grouped.index,\n",
        "            y=grouped.values,\n",
        "            text=grouped.values,\n",
        "            hovertemplate=\n",
        "            \"<b>Category:</b> %{x}<br>\" +\n",
        "            \"<b>Value:</b> %{y}<br>\" +\n",
        "            \"<extra></extra>\"\n",
        "        ))\n",
        "        fig.update_layout(\n",
        "            title=f\"{num_col} by {col_name}\",\n",
        "            xaxis_title=col_name,\n",
        "            yaxis_title=num_col\n",
        "        )\n",
        "        L_mix[j].append([])\n",
        "        L_mix[j][si].append(fig)\n",
        "        si=si+1\n",
        "    j=j+1\n",
        "    \n",
        "for col_index, col_name in enumerate(X_Time):\n",
        "    for num_col in numerical_columns:\n",
        "                grouped = df.groupby(col_name)[num_col].sum()\n",
        "                fig = go.Figure()\n",
        "                fig.add_trace(go.Bar(\n",
        "                    x=grouped.index,\n",
        "                    y=grouped.values,\n",
        "                    text=grouped.values,\n",
        "                    hovertemplate=\n",
        "                    \"<b>Category:</b> %{x}<br>\" +\n",
        "                    \"<b>Value:</b> %{y}<br>\" +\n",
        "                    \"<extra></extra>\"\n",
        "                ))\n",
        "                fig.update_layout(\n",
        "                    title=f\"{num_col} by {col_name}\",\n",
        "                    xaxis_title=col_name,\n",
        "                    yaxis_title=num_col\n",
        "                )\n",
        "                fig.show()\n",
        "# <-------------------------------------------------------------------------------->\n",
        "\n",
        "#Pie charts>>>\n",
        "j=0\n",
        "\n",
        "for i in column_name:\n",
        "    si=0\n",
        "    if len(df[i].unique()) <= 8:\n",
        "        P_single.append([])\n",
        "        counts = df[i].value_counts()\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Pie(\n",
        "            labels=counts.index,\n",
        "            values=counts.values,\n",
        "            hole=0.4,\n",
        "            hovertemplate=\"<b>%{label}</b><br>Count: %{value}<extra></extra>\"\n",
        "        ))\n",
        "        fig.update_layout(\n",
        "            title=f\"Distribution of {i}\",\n",
        "            legend_title=\"Categories\"\n",
        "        )\n",
        "        P_single[j].append([])\n",
        "        P_single[j][si].append(fig)\n",
        "        si=si+1\n",
        "        j=j+1\n",
        "\n",
        "j=0\n",
        "for i in X_Qualitative:\n",
        "    P_mix.append([])\n",
        "    for l in numerical_columns:\n",
        "        si=0\n",
        "        grouped = df.groupby(i)[l].sum()\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Pie(\n",
        "            labels=grouped.index,\n",
        "            values=grouped.values,\n",
        "            hole=0.4,\n",
        "            hovertemplate=\"<b>%{label}</b><br>Value: %{value}<extra></extra>\"\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"Distribution of {l} by {i}\",\n",
        "            legend_title=i\n",
        "        )\n",
        "        P_mix[j].append([])\n",
        "        P_mix[j][si].append(fig)\n",
        "        si=si+1\n",
        "    j=j+1\n",
        "\n",
        "\n",
        "def ensure_datetime(series):\n",
        "    try:\n",
        "        return pd.to_datetime(series, errors='coerce')\n",
        "    except:\n",
        "        return series\n",
        "\n",
        "for d in date_columns:\n",
        "    df[d] = ensure_datetime(df[d])\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df[d]):\n",
        "        continue\n",
        "    for num_col in numerical_columns:\n",
        "\n",
        "# Bar Chart (Aggregated by Month/Year)\n",
        "        df['year'] = df[d].dt.year\n",
        "        df['month'] = df[d].dt.month\n",
        "\n",
        "        monthly = df.groupby('month')[num_col].sum().reset_index()\n",
        "        yearly = df.groupby('year')[num_col].sum().reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "i=-1\n",
        "for all in dia:\n",
        "    i+=1\n",
        "    for j in range(0,len(all)):\n",
        "        for k in range(len(all[j])):\n",
        "            for l in range(len(all[j][k])):\n",
        "                Dia_ID.append(str(i)+str(j)+str(k)+str(l))\n",
        "print(Dia_ID)\n",
        "\n",
        "# Access=[]\n",
        "\n",
        "# for i in range(int(max(Dia_ID)[0])+1):\n",
        "#     Access.append([])\n",
        "#     for val in (Dia_ID):\n",
        "#         if val[0]==str(i):\n",
        "#             Access[i].append(val)\n",
        "# # Access[:] = [x for x in Access if x]\n",
        "# print(Access)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[301], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(Access[pc])):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      4\u001b[0m         p1\u001b[38;5;241m=\u001b[39mdia[\u001b[38;5;28mint\u001b[39m(Access[pc][i][\u001b[38;5;241m0\u001b[39m])][\u001b[38;5;28mint\u001b[39m(Access[pc][i][\u001b[38;5;241m1\u001b[39m])][\u001b[38;5;28mint\u001b[39m(Access[pc][i][\u001b[38;5;241m2\u001b[39m])][\u001b[38;5;28mint\u001b[39m(Access[pc][i][\u001b[38;5;241m3\u001b[39m])]\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# pc=6\n",
        "# for i in range(len(Access[pc])):\n",
        "#     if i ==0:\n",
        "#         p1=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "#     elif i==1:\n",
        "#         p2=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "#     elif i==2:\n",
        "#         p3=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "#     elif i==3:\n",
        "#         p4=dia[int(Access[pc][i][0])][int(Access[pc][i][1])][int(Access[pc][i][2])][int(Access[pc][i][3])]\n",
        "\n",
        "# print(p1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total graphs displayed: 11\n"
          ]
        }
      ],
      "source": [
        "count=0\n",
        "for all in dia:\n",
        "    for i in range(0,len(all)):\n",
        "        for j in range(len(all[i])):\n",
        "            for k in range(len(all[i][j])):\n",
        "                # all[i][j][k].show()\n",
        "                count+=1\n",
        "print(\"Total graphs displayed:\",count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def ensure_datetime(series):\n",
        "#     try:\n",
        "#         return pd.to_datetime(series, errors='coerce')\n",
        "#     except:\n",
        "#         return series\n",
        "\n",
        "# for d in date_columns:\n",
        "#     df[d] = ensure_datetime(df[d])\n",
        "#     if not pd.api.types.is_datetime64_any_dtype(df[d]):\n",
        "#         continue\n",
        "#     for num_col in numerical_columns:\n",
        "# # #Line Chart\n",
        "# #         fig_line = go.Figure()\n",
        "# #         fig_line.add_trace(go.Scatter(\n",
        "# #             x=df[d],\n",
        "# #             y=df[num_col],\n",
        "# #             mode='lines',\n",
        "# #             hovertemplate=\n",
        "# #                 \"<b>Date:</b> %{x}<br>\" +\n",
        "# #                 f\"<b>{num_col}:</b> %{y}<extra></extra>\"\n",
        "# #         ))\n",
        "# #         fig_line.update_layout(\n",
        "# #             title=f\"Line Chart: {num_col} over {d}\",\n",
        "# #             xaxis_title=d,\n",
        "# #             yaxis_title=num_col\n",
        "# #         )\n",
        "# #         fig_line.show()\n",
        "# # Scatter Plot\n",
        "#         # fig_scatter = go.Figure()\n",
        "#         # fig_scatter.add_trace(go.Scatter(\n",
        "#         #     x=df[d],\n",
        "#         #     y=df[num_col],\n",
        "#         #     mode='markers',\n",
        "#         #     hovertemplate=\n",
        "#         #         \"<b>Date:</b> %{x}<br>\" +\n",
        "#         #         f\"<b>{num_col}:</b> %{y}<extra></extra>\"\n",
        "#         # ))\n",
        "#         # fig_scatter.update_layout(\n",
        "#         #     title=f\"Scatter Plot: {num_col} vs {d}\",\n",
        "#         #     xaxis_title=d,\n",
        "#         #     yaxis_title=num_col\n",
        "#         # )\n",
        "#         # fig_scatter.show()\n",
        "# # Area Chart\n",
        "#         # fig_area = go.Figure()\n",
        "#         # fig_area.add_trace(go.Scatter(\n",
        "#         #     x=df[d],\n",
        "#         #     y=df[num_col],\n",
        "#         #     fill='tozeroy',\n",
        "#         #     mode='lines',\n",
        "#         #     hovertemplate=\n",
        "#         #         \"<b>Date:</b> %{x}<br>\" +\n",
        "#         #         f\"<b>{num_col}:</b> %{y}<extra></extra>\"\n",
        "#         # ))\n",
        "#         # fig_area.update_layout(\n",
        "#         #     title=f\"Area Chart: {num_col} over {d}\",\n",
        "#         #     xaxis_title=d,\n",
        "#         #     yaxis_title=num_col\n",
        "#         # )\n",
        "#         # fig_area.show()\n",
        "# # Bar Chart (Aggregated by Month/Year)\n",
        "#         df['year'] = df[d].dt.year\n",
        "#         df['month'] = df[d].dt.month\n",
        "\n",
        "#         monthly = df.groupby('month')[num_col].sum().reset_index()\n",
        "#         yearly = df.groupby('year')[num_col].sum().reset_index()\n",
        "\n",
        "# # # Rolling Average Chart (7-day)\n",
        "# #         df['rolling'] = df[num_col].rolling(7).mean()\n",
        "\n",
        "# #         fig_roll = go.Figure()\n",
        "# #         fig_roll.add_trace(go.Scatter(\n",
        "# #             x=df[d],\n",
        "# #             y=df['rolling'],\n",
        "# #             mode=\"lines\",\n",
        "# #             hovertemplate=\n",
        "# #                 \"<b>Date:</b> %{x}<br>\" +\n",
        "# #                 f\"<b>Rolling Avg ({num_col}):</b> %{y}<extra></extra>\"\n",
        "# #         ))\n",
        "# #         fig_roll.update_layout(\n",
        "# #             title=f\"7-Day Rolling Average of {num_col}\",\n",
        "# #             xaxis_title=d,\n",
        "# #             yaxis_title=num_col\n",
        "# #         )\n",
        "# #         fig_roll.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
